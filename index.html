<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Mercury Currency Engine: Mercury Concurrency Engine</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">Mercury Currency Engine
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Mercury Concurrency Engine </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_README"></a><img src="img/mercury.jpg" alt="mercury" class="inline"/></p>
<h1><a class="anchor" id="autotoc_md1"></a>
Table of Contents</h1>
<ul>
<li><a href="#legal">legal</a></li>
<li><a href="#documentation">documentation</a></li>
<li><a href="#rationale">rationale</a></li>
<li><a href="#prerequisites">prerequisites</a></li>
<li><a href="#building-the-library">building the library</a></li>
<li><a href="#linking-the-library">linking the library</a></li>
<li><a href="#integrating-the-library">integrating the library</a></li>
<li><a href="#building-unit-tests">building unit tests</a></li>
<li><a href="#building-examples">building examples</a></li>
<li><a href="#continuous-integration-tests">continuous integration tests</a></li>
<li><a href="#bug-reports">bug reports</a></li>
<li><a href="#contributing">contributing</a></li>
</ul>
<h1><a class="anchor" id="autotoc_md2"></a>
Legal</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>Licensed under the Apache 2.0 License:</p>
<p><a href="LICENSE.txt">LICENSE.txt</a></p>
<p>You may not use this file except in compliance with the License.</p>
<p>Software distributed under the License is distributed on an "AS IS" BASIS and WITHOUT WARRANTY, either expressed or implied.</p>
<h1><a class="anchor" id="autotoc_md3"></a>
Documentation</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p><a class="el" href="md_high_level_documentation.html">High Level Cpp Coroutine Concurrency Summary</a></p>
<p><a class="el" href="md_concurrency_summary.html">Summary of Concurrent Operations</a></p>
<p><a class="el" href="md_data_communication_summary.html">Summary of Data Communication Operations</a></p>
<p><a href="https://elektrobit.github.io/mercuryconcurrencyengine/">Doxygen Documentation</a></p>
<h2><a class="anchor" id="autotoc_md4"></a>
Generate Doxygen Documentation</h2>
<p><code>doxygen</code> documentation can be generated locally for this library. Install <code>doxygen</code> and <code>graphviz</code> packages then run <code>doxygen</code>: </p><div class="fragment"><div class="line">cd /path/to/your/mce/repo/checkout</div>
<div class="line">doxygen</div>
</div><!-- fragment --><p> The generated <code>doc/</code> directory should contain both <code>html</code> and <code>rtf</code> generated documentation. For <code>html</code>, open <code>index.html</code> by a browser to view the documentation.</p>
<h1><a class="anchor" id="autotoc_md5"></a>
Rationale</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>C++ concurrency is too complicated. Many modern languages implement similar functionality through simpler and/or more expressive mechanisms, often executed at a comparable, or <em>better</em>, speed.</p>
<p>1) Data Communication: It is too hard to share data between different places in code, threaded or otherwise. This library implements channel mechanisms for communicating data in a simple, threadsafe, and templated manner.</p>
<p>2) Concurrency: It is too hard to set up an efficient and easy-to-use concurrency model where <code>std::async</code> is insufficient. Similarly, coroutines are not being leveraged in most C++ applications as a generic way to improve code efficiency. This project implements coroutine mechanisms for concurrency that utilize both coroutines and a generic worker thread backend to efficiently execute tasks in parallel.</p>
<p>This library attempts to address the above concerns by providing a concurrency model that:</p><ul>
<li>leverages coroutines for efficiency improvements</li>
<li>implements simple multithreaded executors</li>
<li>implements communication mechanisms between any combination of coroutines and threads</li>
<li>is easy to use</li>
<li>is extremely fast</li>
<li>is very flexible</li>
<li>is easy to integrate in existing code</li>
</ul>
<h2><a class="anchor" id="autotoc_md6"></a>
What is a coroutine?</h2>
<p>Definition from <a href="https://en.wikipedia.org/wiki/Coroutine">wikipedia</a>: </p><div class="fragment"><div class="line">Coroutines are computer program components that generalize subroutines for non-preemptive multitasking, </div>
<div class="line">by allowing execution to be suspended and resumed. Coroutines are well-suited for implementing familiar </div>
<div class="line">program components such as cooperative tasks, exceptions, event loops, iterators, infinite lists and pipes.</div>
</div><!-- fragment --><p>Coroutines are very useful tools in concurrency because they are both lightweight and extremely fast when context switching. In fact, unit testing in this project reveals some edgecases which are greater than ~10x faster compared to threads (in some extreme edgecases, MUCH faster than that). These properties allow for efficient concurrent algorithms which are otherwise very difficult to write cleanly.</p>
<p>This library makes heavy use of coroutines (provided by <code>Boost.Context</code> and <code>Boost.Coroutine2</code>) to implement its features.</p>
<h2><a class="anchor" id="autotoc_md7"></a>
Why this instead of Boost.Fiber, libdill or C++20 coroutines?</h2>
<p>There are a few reasons to use this instead of other projects like <a href="https://github.com/boostorg/fiber">Boost.Fiber</a>, <a href="https://github.com/sustrik/libdill">libdill</a>, or <a href="https://en.cppreference.com/w/cpp/language/coroutines">c++20 coroutines</a>.</p>
<p>First of all, each of the above frameworks has some very inconvenient drawbacks:</p>
<p><code>Boost.Fiber</code> is more of a "base library", intended to be used in <em>other</em> libraries. It requires a significant investment from the user to integrate and use it. It requires a much higher degree of knowledge to begin implementation, with a higher burden of knowledge required for general developers, due to not having a built in solution for blocking code nor a convenient mechanism for communicating between standard system threads and coroutines. It even requires the user to consider writing their own scheduling algorithms.</p>
<p><code>libdill</code>, a <code>c</code> library, does not implement its framework with multithreading in mind, presupposing that programs would be singlethreaded with coroutines providing concurrency. It's documentation does suggest that multithreading is possible but does not provide much assistance in making it work. No doubt this is ideal in many programs which desire to write their code in <code>c</code>. However, the lack of default multithreaded executors limits the usability and potential scope of the library for many applications (especially ones that don't want to write and debug their own!). Futhermore, because <code>libdill</code> is a <code>c</code> library, it eschews much of the convenience and simplicitly possible in a well designed <code>c++</code> library due to language limitations.</p>
<p>Finally, <code>c++20 coroutines</code> are... an intensely complicated topic. They are extremely fast and lightweight, but just as extremely low level. They are highly structured in a way that limits what can be done with them. Their requirements force any program that utilizes them to design their program around <code>c++20 coroutines</code> at some level rather than simply integrating into existing code. Most of all, they are <em>anything</em> but easy to use. Frankly, I consider them, at least in their current form, a topic only approachable by <code>c++</code> experts, and could not be easily utilized by a broader team.</p>
<p>In comparison, this library attempts to address the various issues from the other frameworks:</p>
<h3><a class="anchor" id="autotoc_md8"></a>
This library's API is very simple</h3>
<p>The mechanisms in this library are designed for simplicity and usability first, instead of as a framework which must provide maximum design flexibility. Mechanisms make use of <code>c++</code> templates to simplify user boilerplate as much as possible.</p>
<p>Scheduling coroutines on backend worker threads is simple, fast, flexible, safe and setup by default. No extra work is required to efficiently schedule coroutine tasks in multithreaded pool of workers. Simply use <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code> (to prefer multi cpu-core scheduling) or <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code> (to prefer scheduling on the current cpu if possible): <a href="ex/src/example_009.cpp">example_009 source</a> </p><div class="fragment"><div class="line">#include &lt;string&gt;</div>
<div class="line">#include &lt;iostream&gt;</div>
<div class="line">#include &lt;mce/mce.hpp&gt;</div>
<div class="line"> </div>
<div class="line">void concurrent_foo(mce::chan&lt;std::string&gt; ch) {</div>
<div class="line">    ch.send(&quot;hello&quot;);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">int main() {</div>
<div class="line">    mce::chan&lt;std::string&gt; ch = mce::chan&lt;std::string&gt;::make();</div>
<div class="line">    mce::concurrent(concurrent_foo,ch);</div>
<div class="line"> </div>
<div class="line">    // interact with concurrent_foo by sending messages over channel object &quot;ch&quot;</div>
<div class="line">    std::string s;</div>
<div class="line">    ch.recv(s);</div>
<div class="line"> </div>
<div class="line">    std::cout &lt;&lt; &quot;received: &quot; &lt;&lt; s &lt;&lt; std::endl;</div>
<div class="line">    return 0;</div>
<div class="line">}</div>
</div><!-- fragment --><p>Terminal output: </p><div class="fragment"><div class="line">$ ./ex/example_009 </div>
<div class="line">received: hello</div>
<div class="line">$</div>
</div><!-- fragment --><p>I have found that writing scheduling algorithms is always a dangerous undertaking. Having scheduling and backend worker thread executors setup by default with a simple API makes coroutines accessible to programmers.</p>
<ul>
<li><code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code>: launch a coroutine, prefering to be launched on the current thread if possible (caller is running on a worker thread) and a background worker thread otherwise. That is, the launched coroutine is concurrent but not guaranteed to be parallel, and typically has the shortest communication latency. This is the recommended default scheduling algorithm.</li>
<li><code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code>: launch a coroutine distributed efficiently across 1 or more background worker threads based on scheduling load. The launched coroutine is concurrent and parallel.</li>
<li><code><a class="el" href="threadpool_8hpp.html#a775daca1186f81e5410f2298abf5b832" title="Launch user function and optional arguments as a coroutine running on a scheduler....">mce::balance()</a></code>: launch a coroutine distributed efficiently across 1 or more background worker threads based on scheduling load. This is a best effort algorithm which prefers to schedule on the calling thread for best-case communication latency, but will schedule on other threads if CPU workload becomes too imbalanced.</li>
</ul>
<p>As a generalized rule:</p><ul>
<li>when CPU throughput is not a bottleneck: a single core is the most efficient (use <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code>)</li>
<li>when CPU throughput is a bottleneck: multiple cores are the most efficient (use <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code>)</li>
<li>when CPU <em>may</em> become a bottleneck: prefer single core but fallback to multiple cores (use <code><a class="el" href="threadpool_8hpp.html#a775daca1186f81e5410f2298abf5b832" title="Launch user function and optional arguments as a coroutine running on a scheduler....">mce::balance()</a></code>)</li>
</ul>
<p>It should be noted that in many or most cases the bottleneck is actually not the CPU throughput. In fact, program bottlenecks are not the real reason for many uses of threads, the user may be leveraging threads for asynchronous behavior in general. In those circumstances, best results will probably be found with <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code>.</p>
<h4><a class="anchor" id="autotoc_md9"></a>
Accessible Low level API:</h4>
<p>The user can manually create and manage the underlying <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> objects to schedule and execute coroutines. If the user desires, they can even create custom <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code> objects to manually manage.</p>
<p>See <a class="el" href="md_concurrency_summary.html">summary of concurrent operations</a> for documentation on all of the above features.</p>
<h3><a class="anchor" id="autotoc_md10"></a>
Ease of Integration</h3>
<p>All concurrent mechanisms in <code>mce</code> are designed to behave correctly whether they are being called from a standard thread (<code>std::thread</code>, generally a <code>pthread</code> under the hood) or being called from within a coroutine (<code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>, a managed <code>boost::coroutines2::coroutine</code> under the hood). <em>This is not a trivial feature</em>, and not all competing <code>c++</code> frameworks attempt it. In particular, none that I know of correctly synchronize between <code>coroutines</code> and code running <em>outside</em> of <code>coroutines</code> like this library does by default.</p>
<p><em>This makes it very easy to integrate this library into existing <code>c++</code> code</em>.</p>
<p>A <code>std::thread</code> calling a <code><a class="el" href="structmce_1_1buffered__channel.html">mce::buffered_channel</a></code>'s <code>send()</code> will behave in a similar way as a <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code> object (executing inside a <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code>) calling <code>send()</code>, even though their blocking mechanisms are completely different underneath.</p>
<p>List of objects and mechanisms which share this interoperability: </p><div class="fragment"><div class="line">mce::unbuffered_channel</div>
<div class="line">mce::buffered_channel</div>
<div class="line">mce::chan</div>
<div class="line">mce::mutex</div>
<div class="line">mce::condition_variable</div>
<div class="line">mce::concurrent()</div>
<div class="line">mce::parallel()</div>
<div class="line">mce::balance()</div>
<div class="line">mce::await()</div>
<div class="line">mce::timer()</div>
<div class="line">mce::sleep()</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md11"></a>
High Level Communication Mechanisms</h3>
<p>A variety of flexible and easy to use communication mechanisms are provided out of the box to handle 99% of communication needs within a single process: </p><div class="fragment"><div class="line">mce::chan // wrap any other channel (a synchronized queue-like object allowing sends and receives)</div>
<div class="line">mce::unbuffered_channel // channel with minimal memory footprint that leverages coroutine context switching efficiency</div>
<div class="line">mce::buffered_channel // channel with configurable memory footprint (buffer size)</div>
<div class="line">mce::await() // block an operation without blocking the calling thread if called by a coroutine</div>
<div class="line">mce::mutex // a replacement for `std::mutex` which works with coroutines and threads, usable with mce::condition_variable</div>
<div class="line">mce::condition_variable // a replacement for `std::condition_variable` for use with `mce::mutex`</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md12"></a>
Trivial blocking operations</h3>
<p>One of the inherent pitfalls of coroutines is that their blocking behavior is managed by the program instead of by the operating system. This means you can cause unexpected deadlock and innefficiency when trying to call any function that blocks a worker thread where coroutines are running. <code>Boost.Fiber</code> specifies the user should either implement non-blocking IO calls or to setup an asynchronous callback mechanism with <code>Boost.Asio</code> to deal with this limitation.</p>
<p>I think this is far too much work to expect of the average programmer (OR an architect, who has many other important things to do) when dealing with something as complex as coroutine concurrency, with far too little gained in efficiency in the average case.</p>
<p>Instead, <code>mce</code> provides a generic <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> function which will provide an <code>std::thread</code> and execute the blocking code there instead. When user function finishes, <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> will resume the <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code> back to the original thread it was running on and return the value of asynchronously executed function.</p>
<p>That is, there's no need to have to manage futures and promises when dealing with <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> calls, you just get the result when it completes: <a href="ex/src/example_001.cpp">example_001 source</a> </p><div class="fragment"><div class="line">#include &lt;fstream&gt;</div>
<div class="line">#include &lt;sstream&gt;</div>
<div class="line">#include &lt;string&gt;</div>
<div class="line">#include &lt;iostream&gt;</div>
<div class="line">#include &lt;mce/mce.hpp&gt;</div>
<div class="line"> </div>
<div class="line">void read_file_content(std::string fname, mce::chan&lt;int&gt; done_ch) {</div>
<div class="line">    std::string fileContent;</div>
<div class="line"> </div>
<div class="line">    // create a function to execute in mce::await() that accesses the caller&#39;s stack </div>
<div class="line">    auto read_file = [&amp;] {</div>
<div class="line">        std::ifstream file(fname); // open file</div>
<div class="line"> </div>
<div class="line">        if(file.is_open()) { </div>
<div class="line">            std::ostringstream ss;</div>
<div class="line">            ss &lt;&lt; file.rdbuf(); // extract file contents</div>
<div class="line">            fileContent = ss.str();</div>
<div class="line">            return true; // await() will return what the input function returns</div>
<div class="line">        } else { </div>
<div class="line">            return false; </div>
<div class="line">        }</div>
<div class="line">    };</div>
<div class="line"> </div>
<div class="line">    // wait for boolean return value of read_file function</div>
<div class="line">    if(mce::await(read_file)) { </div>
<div class="line">        std::cout &lt;&lt; &quot;file successfully read&quot; &lt;&lt; std::endl; </div>
<div class="line">    } else { </div>
<div class="line">        std::cout &lt;&lt; &quot;failed to read file&quot; &lt;&lt; std::endl; </div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    std::cout &lt;&lt; &quot;fileContent: &quot; &lt;&lt; fileContent &lt;&lt; std::endl;</div>
<div class="line">    done_ch.send(0);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">int main(int argc, char** argv) {</div>
<div class="line">    // this is test setup, just ensuring there is a file to read</div>
<div class="line">    std::string fname(&quot;my_filename.txt&quot;);</div>
<div class="line">    std::ofstream file(fname, std::ios_base::trunc);</div>
<div class="line"> </div>
<div class="line">    if(file) {</div>
<div class="line">        file &lt;&lt; &quot;hello world!&quot;;</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    file.close();</div>
<div class="line"> </div>
<div class="line">    // launch asynchronous coroutine to read the file content </div>
<div class="line">    auto done_ch = mce::chan&lt;int&gt;::make(); </div>
<div class="line">    mce::parallel(read_file_content, fname, done_ch);</div>
<div class="line"> </div>
<div class="line">    // wait for coroutine to finish before the program exits</div>
<div class="line">    int r;</div>
<div class="line">    done_ch.recv(r);</div>
<div class="line">    return 0;</div>
<div class="line">}</div>
</div><!-- fragment --><p>Terminal output: </p><div class="fragment"><div class="line">$ ./ex/example_001</div>
<div class="line">file successfully read</div>
<div class="line">fileContent: hello world!</div>
<div class="line">$</div>
</div><!-- fragment --><p>It should be noted that in the above example the function passed to <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> accesses values on the coroutine's stack <em>by reference</em>. This is totally safe because when <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> is executing:</p><ul>
<li>the coroutine or thread calling it will be blocked, meaning there's no competition for accessing values on their stacks</li>
<li>the coroutine or thread calling it will be guaranteed to keep their stack in memory</li>
</ul>
<p>This means it's generally safe to read/write to memory in their stacks <em>by reference</em>. You can think of functions passed to <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> as "executing on the stack" of the caller, even though they are actually executing <em>somewhere else</em>.</p>
<p>If <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> is called outside of a coroutine running on a <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> OR <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> was called inside another call to <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code>, the argument Callable is executed immediately on the current thread instead of on another thread. Otherwise, the calling coroutine will be blocked an the operation passed to <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> will be executed on another, dedicated thread inside another <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code>.</p>
<p>Calls (or implicit calls) to <code><a class="el" href="scheduler_8hpp.html#a8c2a408455943622c5f71f3ff46e5068" title="returns a shared pointer to the scheduler the calling scope is running in">this_scheduler()</a></code>, <code>this_scheduler_ref()</code>, <code><a class="el" href="threadpool_8hpp.html#aff50fe740e3be609a5f698e6dbe8e65e" title="return a reference to the threadpool the calling code is executing in">this_threadpool()</a></code>, or <code>this_threadpool_ref()</code> made within a call to <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> will return the values they would have if they had been called outside of <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code>. That is, code running in <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> will be able to schedule operations as if it was running in its original execution environment. IE, calls to <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code>, <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code>, and <code><a class="el" href="threadpool_8hpp.html#a775daca1186f81e5410f2298abf5b832" title="Launch user function and optional arguments as a coroutine running on a scheduler....">mce::balance()</a></code> will function "normally".</p>
<h4><a class="anchor" id="autotoc_md13"></a>
What about Networking or other Features?</h4>
<p>A common feature in coroutine frameworks is the presence of ipv4/ipv6 support. Said frameworks want to provide a coroutine compatible API for said operations. IE, networking is, by design, a blocking task, and blocking tasks running in a coroutine scheduling environment can introduce latency or deadlock.</p>
<p>However, it should be pointed out that the real problem here is not that networking "functionality" creates problems for coroutines but the fact that networking <em>features</em> are <em>blocking</em>. As discussed in the previous section, blocking tasks can be passed to <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> for execution where they won't affect scheduling of any other coroutines. Additionally, because communication channels work in both coroutines and standard threads, the task executing in <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> (or any other <code>std::thread</code>) can communicate back to running coroutines using said channels. This allows the user to use <em>whatever</em> standard networking implementation they desire and route the results back into the coroutine environment when they are available.</p>
<p>The main consideration the user may need to make when executing blocking networking operations in <code>mce:<a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">await()</a></code> calls is the number of default await worker threads they want available by default. <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> will spawn additional threads as necessary, but it tries to keep a preconfigured number of reusable worker threads in existence. If the user is consistently executing many blocking calls they can consider spawning more reusable worker threads to improve efficiency. This count of worker threads can be modified in this library's toplevel <code>CMakeLists.txt</code> by modifying the <code>MCEMINAWAITPROCS</code> variable.</p>
<h1><a class="anchor" id="autotoc_md14"></a>
Prerequisites</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<h3><a class="anchor" id="autotoc_md15"></a>
Environment</h3>
<p>This project is designed for a POSIX linux environment.</p>
<h3><a class="anchor" id="autotoc_md16"></a>
Libraries</h3>
<p>The following POSIX libraries are required:</p><ul>
<li>pthread // it is potentially possible that a different threading library is required depending on OS configuration</li>
</ul>
<p>This library directly utilizes the following <a href="https://www.boost.org/">boost</a> libraries:</p><ul>
<li>boost/coroutine2</li>
<li>boost/context</li>
</ul>
<p>As well as the following boost header only libraries (and dependencies):</p><ul>
<li>boost/circular_buffer</li>
</ul>
<p>It should be noted that the boost features are automatically downloaded and built from source for this project, as necessary.</p>
<h3><a class="anchor" id="autotoc_md17"></a>
Tools</h3>
<ul>
<li>c++11 compiler toolchain</li>
<li>cmake</li>
<li>make</li>
<li>python3</li>
<li>wget</li>
<li>tar</li>
</ul>
<h1><a class="anchor" id="autotoc_md18"></a>
Building the library</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>If you want to build unit tests you will need to checkout submodules for the googletest framework: </p><div class="fragment"><div class="line">git clone --recurse-submodules git@github.com:Elektrobit/mercuryconcurrencyengine.git</div>
</div><!-- fragment --><p>Building on linux: </p><div class="fragment"><div class="line">cmake .</div>
<div class="line">make mce</div>
</div><!-- fragment --><p>Which produces the static library: </p><div class="fragment"><div class="line">libmce.a</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md19"></a>
Boost Version</h2>
<p>The library build <code>make</code> targets will download and build <code>boost</code> from source if the specified version of boost source code is not available. The version of boost can be configured by modifying the following variables in the <a href="CMakeLists.txt">CMakeLists.txt</a>: </p><div class="fragment"><div class="line">set(MCE_BOOST_MAJOR_VERSION 1)</div>
<div class="line">set(MCE_BOOST_MINOR_VERSION 85)</div>
<div class="line">set(MCE_BOOST_PATCH_VERSION 0)</div>
</div><!-- fragment --><p>If the boost download url becomes outdated, consider either updating the <code>MCE_BOOST_DOWNLOAD_URL</code> <code>CMake</code> variable.</p>
<h3><a class="anchor" id="autotoc_md20"></a>
Pre-downloaded Boost</h3>
<p>You can manually download and extract boost in the root of this repository to <code>boost/boost_major_minor_patch</code> (replace <code>major</code>, <code>minor</code>, and <code>patch</code> with appropriate version values and be sure to update the <code>CMakeLists.txt</code> <code>MCE_BOOST_MAJOR_VERSION</code>, <code>MCE_BOOST_MINOR_VERSION</code>, and <code>MCE_BOOST_PATCH_VERSION</code> variables).</p>
<p>Doing this will skip the <code>boost</code> download step.</p>
<h3><a class="anchor" id="autotoc_md21"></a>
Pre-built Boost</h3>
<p>It is also possible to use linux symlinks to point to a <em>prebuilt</em> <code>boost</code> version. After making the symlink, you will need to create a file called <code>boost.built</code> in the project's root (with a command doing something like: <code>touch boost.built</code>).</p>
<p>WARNING: If you use a <em>prebuilt</em> version of <code>boost</code>, you <em>MUST</em> ensure that the following features are built: </p><div class="fragment"><div class="line">context </div>
<div class="line">coroutine</div>
<div class="line">thread</div>
</div><!-- fragment --><p>You can do this by passing the following arguments to <code>b2</code> when building <code>boost</code>: </p><div class="fragment"><div class="line">--with-context --with-coroutine --with-thread</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md22"></a>
Configuring library threadcounts</h2>
<p>The following features can be configured <code>ON</code>/<code>OFF</code> enable or disable compile time defines which configure or disable default background threads: </p><div class="fragment"><div class="line"># Define the count of threads in the background default threadpool accessed by </div>
<div class="line"># features like `mce::parallel()`. If `0` is set (the default), the library will </div>
<div class="line"># decide how many threads to spawn, preferring maximum CPU throughput.</div>
<div class="line">set(MCEMAXPROCS 0)</div>
<div class="line"> </div>
<div class="line"># Define the minimum count of available threads for await tasks executed by </div>
<div class="line"># `mce::await()` (more will be temporarily spawned as necessary).</div>
<div class="line">set(MCEMINAWAITPROCS 1)</div>
</div><!-- fragment --><p>The general design of a default compilation of this framework is to provide the following:</p><ul>
<li>N background worker threads (where N is equal to the number of CPU cores)</li>
<li>1 reusable background await thread (more will temporarily spawn as necessary)</li>
<li>1 background timer thread</li>
</ul>
<p>There will also be the main thread the process spawns on, so the total default threadcount after initialization is N+3.</p>
<h3><a class="anchor" id="autotoc_md23"></a>
Building the library with minimal threadcount</h3>
<p>In many cases, having a minimal count of background worker threads is ideal. This is because many (most?) programs are not bottlenecked by CPU throughput, and will benefit instead from minimal coroutine communication latency.</p>
<p>The <code>mce_minimal</code> <code>make</code> target is the equivalent of setting </p><div class="fragment"><div class="line">set(MCEMAXPROCS 1)</div>
</div><!-- fragment --><p>Which limits the default threadpool to 1 worker thread. When heavy parallelization is not required, and the user only needs the efficiency gains and design simplicity of coroutines, this is a useful target to link against as this will enforce singlethreaded coroutine execution.</p>
<p>Building on linux </p><div class="fragment"><div class="line">cmake .</div>
<div class="line">make mce_minimal</div>
</div><!-- fragment --><p>Which produces the static library: </p><div class="fragment"><div class="line">libmce_minimal.a</div>
</div><!-- fragment --><p>Doing this will set the background executor to build with only 1 worker thread. Leaving all other options on their defaults, this results in your process launching with access to 4 default threads:</p><ul>
<li>main thread</li>
<li>coroutine executor background worker thread</li>
<li>await background worker thread (more will be spawned as necessary)</li>
<li>timer background thread</li>
</ul>
<p>The 3 non-main threads will block and take no further resources until needed. This pattern is suprisingly useful, as the main thread can launch all other operations on the coroutine background worker thread using <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code>. If interprocess communication is necessary, the main thread can begin listening for messages at this point, otherwise it can block.</p>
<p>A program designed for <code>mce</code> multithreaded execution (IE, explicit calls to <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code> and <code><a class="el" href="threadpool_8hpp.html#a775daca1186f81e5410f2298abf5b832" title="Launch user function and optional arguments as a coroutine running on a scheduler....">mce::balance()</a></code>) will still function in this environment. In fact, assuming the user is not manually using custom <code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool</a></code> objects, <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code> and <code><a class="el" href="threadpool_8hpp.html#a775daca1186f81e5410f2298abf5b832" title="Launch user function and optional arguments as a coroutine running on a scheduler....">mce::balance()</a></code> become nearly indistinguishable from <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code> when operating with a single executor thread, they "Just Work".</p>
<p>It should be noted that scheduling exclusively with <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">ccc::concurrent()</a></code> will provide similar behavior to compiling against <code>mce_minimal</code>, so if your program already is written with singlethreaded concurrency in mind, it may be unecessary to change link targets (though doing so will save a small amount of memory).</p>
<h1><a class="anchor" id="autotoc_md24"></a>
Linking the library</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>To link against and use this library you will need to add the boost root (IE, <code>boost/boost_1_85_0/</code>) and the <code>mce</code> <code>inc/</code> directory to your program's include flags.</p>
<p>Similarly you will need to instruct the linker about the boost lib and <code>mce</code> project root directories to find the relevant libraries (like <code>libmce.a</code>/<code>libmce_minimal.a</code>).</p>
<p>Given some shell environment variable named <code>MCE_ROOT</code> (which points to the <code>mce</code> project's root directory) here is a trivial Makefile illustrating how to link against the dependencies when using this library: </p><div class="fragment"><div class="line">CC=g++</div>
<div class="line">CFLAGS+=&quot;-I$MCE_ROOT/boost/boost_1_85_0 &quot;</div>
<div class="line">CFLAGS+=&quot;-I$MCE_ROOT/inc &quot;</div>
<div class="line">LDFLAGS+=&quot;-L$MCE_ROOT/boost/boost_1_85_0/stage/lib -L$MCE_ROOT &quot;</div>
<div class="line">LIBS=-lmce -lboost_coroutine -lboost_context -lpthread</div>
<div class="line"> </div>
<div class="line">yourprogram: yourprogram.cpp</div>
<div class="line">    $(CC) $(LDFLAGS) $(CFLAGS) yourprogram.cpp $(LIBS) -o yourprogram</div>
<div class="line"> </div>
<div class="line">clean: </div>
<div class="line">    rm yourprogram</div>
</div><!-- fragment --><p>You can then include <code>#include &lt;<a class="el" href="mce_8hpp.html">mce/mce.hpp</a>&gt;</code> (or any other header in <code>inc/mce/</code>). Example yourprogram.cpp: <a href="ex/src/example_009.cpp">example_009 source</a> </p><div class="fragment"><div class="line">#include &lt;string&gt;</div>
<div class="line">#include &lt;iostream&gt;</div>
<div class="line">#include &lt;mce/mce.hpp&gt;</div>
<div class="line"> </div>
<div class="line">void concurrent_foo(mce::chan&lt;std::string&gt; ch) {</div>
<div class="line">    ch.send(&quot;hello&quot;);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">int main() {</div>
<div class="line">    mce::chan&lt;std::string&gt; ch = mce::chan&lt;std::string&gt;::make();</div>
<div class="line">    mce::concurrent(concurrent_foo,ch);</div>
<div class="line"> </div>
<div class="line">    // interact with concurrent_foo by sending messages over channel object &quot;ch&quot;</div>
<div class="line">    std::string s;</div>
<div class="line">    ch.recv(s);</div>
<div class="line"> </div>
<div class="line">    std::cout &lt;&lt; &quot;received: &quot; &lt;&lt; s &lt;&lt; std::endl;</div>
<div class="line">    return 0;</div>
<div class="line">}</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md25"></a>
Integrating the Library</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>Integrating any framework into an existing codebase is an art unto itself. However, this library is simpler to integrate compared to others of its kind because most code will function as normal when running in a coroutine or can be easily wrapped. For any code you wish to migrate to this framework, the following is suggested:</p>
<h2><a class="anchor" id="autotoc_md26"></a>
Feature Checklist</h2>
<p>Based on your program requirements, specify values in the <code>CMakeLists.txt</code> before building, if necessary:</p><ul>
<li>Background Executor Threadcount: control with <code>MCEMAXPROCS</code></li>
<li>Background Await Threadcount: control with <code>MCEMINAWAITPROCS</code></li>
</ul>
<h2><a class="anchor" id="autotoc_md27"></a>
Integration Checklist</h2>
<p>For all code that needs to be migrated to this library, complete the following checklist:</p><ul>
<li>replace all relevant usage of <code>std::thread</code>s or <code>pthread</code>s with <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code>/<code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code> etc.</li>
<li>replace all relevant usage of <code>std::mutex</code> or <code>pthread_mutex_t</code> with <code><a class="el" href="structmce_1_1mutex.html">mce::mutex</a></code></li>
<li>replace all relevant usage of <code>std::condition_variable</code> or <code>pthread_cond_t</code> with <code><a class="el" href="structmce_1_1condition__variable.html">mce::condition_variable</a></code></li>
<li>wrap all other blocking or system calls with <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code></li>
<li>implement calls to <code><a class="el" href="structmce_1_1lifecycle.html#a40ca609098ab385d9edb4afd464c28ee" title="temporarily suspend operations">mce::threadpool::suspend()</a></code>/<code><a class="el" href="structmce_1_1lifecycle.html#a9f09571422351f21ddf3e6d127d0d708" title="resume any current or future call to run() after an suspend()">mce::threadpool::resume()</a></code>/<code><a class="el" href="structmce_1_1lifecycle.html#a07bf9e349c9636ae62ae979daae4a586" title="halt and join lifecycle execution">mce::threadpool::halt()</a></code> and/or <code><a class="el" href="structmce_1_1scheduler.html#a5bbddf1f71d61a95b84948c23ae218ac">mce::scheduler::run()</a></code>/<code><a class="el" href="structmce_1_1lifecycle.html#a40ca609098ab385d9edb4afd464c28ee" title="temporarily suspend operations">mce::scheduler::suspend()</a></code>/<code><a class="el" href="structmce_1_1lifecycle.html#a9f09571422351f21ddf3e6d127d0d708" title="resume any current or future call to run() after an suspend()">mce::scheduler::resume()</a></code>/<code><a class="el" href="structmce_1_1lifecycle.html#a07bf9e349c9636ae62ae979daae4a586" title="halt and join lifecycle execution">mce::scheduler::halt()</a></code> to properly pause/unpause/stop coroutine execution during process lifecycle changes. The default threadpool <code><a class="el" href="threadpool_8hpp.html#af318b6bdd9e8e98245499ea41720208a" title="return the default threadpool&#39;s">mce::default_threadpool()</a></code> only needs <code>suspend()</code>/<code>resume()</code> to be called (<code>run()</code>/<code>halt()</code> are called by the library in this case).</li>
</ul>
<p>If the user encounters deadlock, that is an indication that some blocking code was not properly addressed. Pay careful attention to the behavior of internal library code, and consider wrapping its blocking calls with <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code>. If some code proves particularly difficult to wrap with <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code>, consider leaving that code running on a separate system thread.</p>
<p>Assuming the user has relevant stress testing implemented the above should be sufficient to demonstrate categorical improvements to user code efficiency.</p>
<h2><a class="anchor" id="autotoc_md28"></a>
Additional Integration Improvements Checklist</h2>
<p>Here are other efficiency improvement steps that can be taken when integrating this library (ordered from most to least important):</p><ul>
<li>replace interthread message passing and communication with channels. IE, channels are generally faster than raw mutex/conditions.</li>
<li>if many <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> calls are being made, rebuild this framework with <code>MCEMINAWAITPROCS</code> set greater than <code>1</code>, as needed, so fewer threads need to be regularly spawned &amp; destroyed.</li>
<li>replace any slow timer usage (such as interprocess timers) with calls to <code><a class="el" href="timer_8hpp.html#a4f3d651eea461040f92652f0f2455ea0" title="launch a timer with a Callable to be called on timeout">mce::timer()</a></code>/<code><a class="el" href="timer_8hpp.html#ae0c5845b438107a32cdde80510a3f5f7" title="Access to default mce::timer_service object.">mce::default_timer_service()</a>-&gt;<a class="el" href="timer_8hpp.html#a4f3d651eea461040f92652f0f2455ea0" title="launch a timer with a Callable to be called on timeout">timer()</a></code></li>
<li>rewrite any algorithms that need to be concurrent, but not parallel, with <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code> or <code><a class="el" href="scheduler_8hpp.html#a8c2a408455943622c5f71f3ff46e5068" title="returns a shared pointer to the scheduler the calling scope is running in">mce::this_scheduler()</a>-&gt;schedule()</code> to reduce communication latency introduced by unnecessarily running code on separate CPU cores.</li>
<li>rewrite complicated asynchronous algorithms to benefit from direct coroutine channel communication, rather than abstracted through many levels of boilerplate. This will improve code clarity and may improve efficiency as well. IE, it's much easier to understand and debug two functions talking through a channel than a complicated array of asynchronous callbacks and state checks</li>
</ul>
<h1><a class="anchor" id="autotoc_md29"></a>
Building unit tests</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>From repository toplevel </p><div class="fragment"><div class="line">cmake .  </div>
<div class="line">make mce_ut  </div>
</div><!-- fragment --><p>run unit tests: </p><div class="fragment"><div class="line">./tst/mce_ut</div>
</div><!-- fragment --><p>Tests are written using gtest and therefore can filter which tests will actually execute using <code>--gtest_filter="your regular expression here"</code> as an argument provided to <code>mce_ut</code>.</p>
<h1><a class="anchor" id="autotoc_md30"></a>
Building examples</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>From repository toplevel </p><div class="fragment"><div class="line">cmake .  </div>
<div class="line">make mce_ex</div>
</div><!-- fragment --><p>run unit examples (replace NNN with specific example number): </p><div class="fragment"><div class="line">./ex/example_NNN</div>
</div><!-- fragment --><p>Below is the code for a standalone program from example code included in <code>ex/src</code>.</p>
<p><a href="ex/src/example_002.cpp">example_002 source</a> </p><div class="fragment"><div class="line">// example_002</div>
<div class="line">#include &lt;iostream&gt;</div>
<div class="line">#include &quot;mce.hpp&quot;</div>
<div class="line"> </div>
<div class="line">int main()</div>
<div class="line">{</div>
<div class="line">  const int max = 10;</div>
<div class="line">  auto ch = mce::chan&lt;int&gt;::make();</div>
<div class="line">  auto done_ch = mce::chan&lt;bool&gt;::make();</div>
<div class="line"> </div>
<div class="line">  auto sender = [](int max, mce::chan&lt;int&gt; ch)</div>
<div class="line">  { </div>
<div class="line">      for(int i=0; i&lt;max; ++i)</div>
<div class="line">      { </div>
<div class="line">          ch.send(i); </div>
<div class="line">      }</div>
<div class="line">      ch.close();</div>
<div class="line">  };</div>
<div class="line"> </div>
<div class="line">  auto receiver = [](int max, mce::chan&lt;int&gt; ch, mce::chan&lt;bool&gt; done_ch)</div>
<div class="line">  { </div>
<div class="line">      for(auto&amp; i : ch)</div>
<div class="line">      {</div>
<div class="line">          std::cout &lt;&lt; i &lt;&lt; std::endl;</div>
<div class="line">      }</div>
<div class="line">      done_ch.send(true); </div>
<div class="line">  };</div>
<div class="line"> </div>
<div class="line">  mce::parallel(sender, max, ch);</div>
<div class="line">  mce::parallel(receiver, max, ch, done_ch);</div>
<div class="line">  bool r;</div>
<div class="line">  done_ch.recv(r);</div>
<div class="line">  return 0;</div>
<div class="line">}</div>
</div><!-- fragment --><h3><a class="anchor" id="autotoc_md31"></a>
terminal output</h3>
<div class="fragment"><div class="line">$ ./ex/example_002</div>
<div class="line">0</div>
<div class="line">1</div>
<div class="line">2</div>
<div class="line">3</div>
<div class="line">4</div>
<div class="line">5</div>
<div class="line">6</div>
<div class="line">7</div>
<div class="line">8</div>
<div class="line">9</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md32"></a>
Continuous Integration Tests</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>The python script <code>continuous_integration.py</code> is to be run with <code>python3 ./script/continuous_integration.py</code>. It builds and runs all enabled unit tests and examples, to generally verify everything is working. Running this may take a long time. It may also heavily tax your system's cpu resources.</p>
<p>Continuous integration tests require both <code>gcc/g++</code> and <code>clang/clang++</code> toolchains to be installed on the system in their normal locations (<code>/usr/bin/</code>). Testing attempts to be fairly exhaustive.</p>
<h1><a class="anchor" id="autotoc_md33"></a>
Bug Reports</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>If you are having issues with the code that is not solved by the help provided in the documentation:</p>
<p><a class="el" href="md_high_level_documentation.html">High Level Cpp Coroutine Concurrency Summary</a></p>
<p><a class="el" href="md_concurrency_summary.html">Summary of Concurrent Operations</a></p>
<p><a class="el" href="md_data_communication_summary.html">Summary of Data Communication Operations</a></p>
<p><a href="https://elektrobit.github.io/mercuryconcurrencyengine/">Doxygen Documentation</a></p>
<p>Then you are welcome to report an issue in the Issues tab. In your issue please include:</p><ol type="1">
<li>A clear, well written explanation of what you are trying to accomplish</li>
<li>A clear, well written explanation of the error</li>
<li>All necessary snippets of code that are failing</li>
<li>A copy, verbatim, of any error text reported by the compiler or executing environment</li>
<li>Information about your executing hardware: processor model, processor specs, RAM specs, etc.</li>
<li>Information about your executing environment: OS &amp; OS version, build environment (ie, gcc or clang, cmake or gradle, etc. along with version information for said tools), build settings (the actual arguments given to each tool), etc.</li>
</ol>
<h1><a class="anchor" id="autotoc_md34"></a>
Contributing</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>Contributions to this project are welcome, please read this primer for instructions on how to contribute </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
