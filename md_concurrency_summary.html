<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>CppCoroutineCurrency: Summary of Concurrent Operations</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">CppCoroutineCurrency
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Summary of Concurrent Operations </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="autotoc_md50"></a>
A word about channels</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>All <code>mce</code> channel objects correctly communicate data between coroutines, threads, or any combination of the two in a threadsafe/coroutinesafe way. These objects are HIGHLY RECOMMENDED as the primary method of communication between concurrent code, because they are extremely simple in practice and cover most communication usecases. See <a class="el" href="md_data_communication_summary.html">Data Communication Summary</a>. More examples of channel usage are available throughout the documentation, including below in this file.</p>
<p>If an edgecase occurs where mutexes &amp; condition variables would be the preferred solution, see <code>mutex</code> and <code>condition_variable</code> in the <code>united synchronization primatives</code> section of <code>High Level Concurrency</code>.</p>
<p>Note that all channels are automatically included as part of <code><a class="el" href="mce_8hpp.html">mce/mce.hpp</a></code>.</p>
<h1><a class="anchor" id="autotoc_md51"></a>
Concurrency Table of Contents</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>All concurrent code is included with the header <code><a class="el" href="mce_8hpp.html">mce/mce.hpp</a></code></p><ul>
<li><a href="#concurrency-design">Concurrency Design</a></li>
<li><a href="#high-level-concurrency">High Level Concurrency</a></li>
<li><a href="#low-level-concurrency">Low Level Concurrency</a></li>
<li><a href="#concurrent-lifecycle-management">Concurrent Lifecycle Management</a></li>
</ul>
<hr  />
 <h1><a class="anchor" id="autotoc_md53"></a>
Concurrency Design</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>It should be noted that concurrency and scheduling algorithms are always an imperfect art form. There is no "one scheduling algorithm to rule them all", because the proper scheduling algorithm is determined by the actual design and needs of a program. For instance, most of the time the best scheduling algorithm... is to not schedule anything (just execute right there)! However, where this is not possible or preferrable, there are a there are a few categories of thinking that can help when programming a general "best effort" program which uses concurrency.</p>
<p>This first is to identify whether a piece of code needs concurrency:</p><ul>
<li>for CPU throughput</li>
<li>or for asynchronous behavior generally</li>
</ul>
<p>In the first case, a simple way to break a program down is to identify the "parts" of the program which need to do categorically different things. That is, if you can entirely separate pieces of the program which can act independently (for instance, into separate service objects), then those separate components are good candidates for being scheduled in parallel (with <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code>, <code>mce::threadpool::schedule()</code>, or <code><a class="el" href="threadpool_8hpp.html#af318b6bdd9e8e98245499ea41720208a" title="return the default threadpool&#39;s">mce::default_threadpool()</a>-&gt;schedule()</code>).</p>
<p>However, it should be noted that just because something can be parallelized, doesn't mean benefits will outweigh the negatives. It is easy to seriously underestimate how efficient coroutine scheduling is. As such, it may be best to schedule with <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code> instead of <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code> until testing reveals the need for parallelization.</p>
<p>In the second case, you can further break down code's concurrency needs into:</p><ul>
<li>wants fast communication speed between code which cannot operate synchronously</li>
<li>the operation is blocking and needs to be asynchronously resumed</li>
</ul>
<p>If communication speed is the need, child tasks spawned from parent tasks that where themselves scheduled in parallel (on different threads) can often (but not <em>always</em>), be trivially scheduled with <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code>, which will give the fastest communication speed. Assuming the program is operating in an environment where it's resources are not being pushed to its limit (hopefully most of the time :-) ) then this will generally give you what you want.</p>
<p>It should be noted, that a program which <em>only</em> schedules with <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code> will often be good enough, and probably exceptionally performant. Because of this, mass usage of <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code> is recommended for most programs, as the resulting performance should be quite good. If some operation is noted to be especially CPU intensive, it can always be explicitly scheduled with <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code>.</p>
<p>Alternatively, if some operation is blocking or otherwise asynchronous, alternative concurrent solutions become useful:</p><ul>
<li><code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code>: block the caller until the launched task completes</li>
<li><code><a class="el" href="timer_8hpp.html#a4f3d651eea461040f92652f0f2455ea0" title="launch a timer with a Callable to be called on timeout">mce::timer()</a></code>: block the caller until a timeout occurs and execute a callback</li>
<li><code><a class="el" href="timer_8hpp.html#abccb4fe0939b4eb26cd7e8a70c3b33d2" title="Put coroutine or thread to sleep in a blocking fashion.">mce::sleep()</a></code>: block the caller until a timeout occurs</li>
</ul>
<p>There are many edgecases where the above is insufficient, but I believe they are good guidelines for writing code that behaves well in most circumstances.</p>
<h1><a class="anchor" id="autotoc_md54"></a>
High Level Concurrency</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<ul>
<li><a href="#concurrent">concurrent</a></li>
<li><a href="#parallel">parallel</a></li>
<li><a href="#balance">balance</a></li>
<li><a href="#custom-scheduling">custom scheduling</a></li>
<li><a href="#yield">yield</a></li>
<li><a href="#await">await</a></li>
<li><a href="#timer">timer</a></li>
<li><a href="#sleep">sleep</a></li>
<li><a href="#united-synchronization-primatives">united synchronization primatives</a></li>
</ul>
<hr  />
 <h2><a class="anchor" id="autotoc_md56"></a>
schedule</h2>
<p><code><a class="el" href="structmce_1_1scheduler.html#a013cd1b794606776a4c409f50ac437f1" title="schedule allocated coroutine(s)">mce::scheduler::schedule()</a></code> is also addressed in the <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> section. However, because of its importance to higher level API, it is examined first here: </p><div class="fragment"><div class="line">namespace mce {</div>
<div class="line"> </div>
<div class="line">struct scheduler {</div>
<div class="line">    /**</div>
<div class="line">     @brief Schedule allocated coroutines</div>
<div class="line"> </div>
<div class="line">     Arguments to this function can be:</div>
<div class="line">     - an allocated `std::unique_ptr&lt;mce::coroutine&gt;`</div>
<div class="line">     - an iterable container of allocated `std::unique_ptr&lt;mce::coroutine&gt;`s</div>
<div class="line"> </div>
<div class="line">     After the above argument types, any remaining arguments can be:</div>
<div class="line">     - a Callable (followed by any arguments for the Callable) </div>
<div class="line"> </div>
<div class="line">     The user can manually construct allocated </div>
<div class="line">     `std::unique_ptr&lt;mce::coroutine&gt;`s with `mce::coroutine::make()`</div>
<div class="line"> </div>
<div class="line">     Multi-argument schedule()s hold the scheduler&#39;s lock throughout (they are </div>
<div class="line">     simultaneously scheduled).</div>
<div class="line"> </div>
<div class="line">     @param a the first argument</div>
<div class="line">     @param as any remaining arguments</div>
<div class="line">     */</div>
<div class="line">    template &lt;typename A, typename... As&gt;</div>
<div class="line">    void schedule(A&amp;&amp; a, As&amp;&amp;... as);</div>
<div class="line">};</div>
<div class="line"> </div>
<div class="line">}</div>
</div><!-- fragment --><p><code><a class="el" href="structmce_1_1scheduler.html#a013cd1b794606776a4c409f50ac437f1" title="schedule allocated coroutine(s)">mce::scheduler::schedule()</a></code> is an extremely flexible templated mechanism. Higher level operations pass their arguments directly to it, so all features and behavior are inherited by those mechanisms (<code>mce::threadpool::schedule()</code>, <code><a class="el" href="threadpool_8hpp.html#af318b6bdd9e8e98245499ea41720208a" title="return the default threadpool&#39;s">mce::default_threadpool()</a>-&gt;schedule()</code>, <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code>, <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code>, <code><a class="el" href="threadpool_8hpp.html#a775daca1186f81e5410f2298abf5b832" title="Launch user function and optional arguments as a coroutine running on a scheduler....">mce::balance()</a></code>).</p>
<hr  />
 <h2><a class="anchor" id="autotoc_md58"></a>
concurrent</h2>
<div class="fragment"><div class="line">/// Schedule a coroutine(s), preferring best communication latency</div>
<div class="line">template &lt;typename... As&gt;</div>
<div class="line">void mce::concurrent(As&amp;&amp;... args)</div>
</div><!-- fragment --><p> <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code> passes it's arguments to <code><a class="el" href="structmce_1_1scheduler.html#a013cd1b794606776a4c409f50ac437f1" title="schedule allocated coroutine(s)">mce::scheduler::schedule()</a></code> as-is. Executes its arguments as a concurrent coroutine(s). It attempts to intelligently schedule coroutines using the following algorithm:</p><ul>
<li>the <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> for the current thread (if running inside a <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code>), or</li>
<li>a default <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> (running in the <code><a class="el" href="threadpool_8hpp.html#af318b6bdd9e8e98245499ea41720208a" title="return the default threadpool&#39;s">mce::default_threadpool()</a></code>) as a final fallback.</li>
</ul>
<p>This is useful shorthand for writing a concurrent algorithm which gains more potential communication efficiency from faster context switching than from optimal task distribution across available CPU cores.</p>
<p>That is, if the following are true:</p><ol type="1">
<li><code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code> is being called from within a coroutine</li>
<li>the function being scheduled as a coroutine will need to communicate quickly or frequently with other coroutines scheduled on the current thread</li>
</ol>
<p>Then <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code> may provide better performance than <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code> because the arguments will attempt to be scheduled on the current thread, as opposed to potentially scheduling on and synchronizing with a <em>different</em> thread, which can add significant overhead when the coroutines running on different threads need to communicate.</p>
<hr  />
 <h2><a class="anchor" id="autotoc_md60"></a>
parallel</h2>
<div class="fragment"><div class="line">/// Schedule a coroutine(s), preferring max CPU throughput</div>
<div class="line">template &lt;typename... As&gt;</div>
<div class="line">void mce::parallel(As&amp;&amp;... args);</div>
</div><!-- fragment --><p> <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code> passes it's arguments to <code><a class="el" href="structmce_1_1scheduler.html#a013cd1b794606776a4c409f50ac437f1" title="schedule allocated coroutine(s)">mce::scheduler::schedule()</a></code> as-is. Executes its arguments as a concurrent coroutine(s). It attempts to intelligently schedule coroutines using the following algorithm:</p><ul>
<li>on the <code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool</a></code> assigned to the calling thread (in the case that the code is already executing in a <code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool</a></code>), or</li>
<li>the <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> for the current thread (if running inside a <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code>), or</li>
<li>the default <code>mce:::threadpool</code> as a final fallback (acquired by calling <code><a class="el" href="threadpool_8hpp.html#af318b6bdd9e8e98245499ea41720208a" title="return the default threadpool&#39;s">mce::default_threadpool()</a></code>, see low level concurrency for more information).</li>
</ul>
<p><code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code> is useful when it is known that operations should be parallelized to a high degree. The most common case this will occur is if there is a highly CPU intensive operation(s) that need to be spawned sometime after program startup.</p>
<p>NOTE: Even when properly distributed across CPU cores, CPU intensive operations which run for a long time will still block their system thread. If long running CPU intensive operations are causing problems, insert calls to <code><a class="el" href="coroutine_8hpp.html#a43169feccceeceeb2b4ce668671196df">mce::yield()</a></code> to suspend them regularly and let other code run.</p>
<p><a href="ex/src/example_014.cpp">example_014 source</a> </p><div class="fragment"><div class="line">// example_014 </div>
<div class="line">#include &lt;iostream&gt;</div>
<div class="line">#include &quot;mce.hpp&quot;</div>
<div class="line"> </div>
<div class="line">void print_threadpool_address()</div>
<div class="line">{</div>
<div class="line">    // just for synchronizing prints</div>
<div class="line">    static mce::mutex mtx;</div>
<div class="line">    std::unique_lock&lt;mce::mutex&gt; lk(mtx);</div>
<div class="line">    std::cout &lt;&lt; &quot;threadpool address[&quot; </div>
<div class="line">              &lt;&lt; &amp;(mce::this_threadpool())</div>
<div class="line">              &lt;&lt; &quot;]&quot;</div>
<div class="line">              &lt;&lt; std::endl;</div>
<div class="line">};</div>
<div class="line"> </div>
<div class="line">void some_function(mce::chan&lt;int&gt; done_ch)</div>
<div class="line">{</div>
<div class="line">    // should print tp address</div>
<div class="line">    print_threadpool_address();</div>
<div class="line">    done_ch.send(0);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">int main()</div>
<div class="line">{</div>
<div class="line">    mce::chan&lt;int&gt; done_ch = mce::chan&lt;int&gt;::make();</div>
<div class="line">    auto tp = mce::threadpool::make();</div>
<div class="line"> </div>
<div class="line">    std::cout &lt;&lt; &quot;tp address[&quot; &lt;&lt; tp.get() &lt;&lt; &quot;]&quot; &lt;&lt; std::endl;</div>
<div class="line">    std::cout &lt;&lt; &quot;default threadpool address[&quot; </div>
<div class="line">              &lt;&lt; &amp;(mce::default_threadpool())</div>
<div class="line">              &lt;&lt; &quot;]&quot; </div>
<div class="line">              &lt;&lt; std::endl;</div>
<div class="line">    </div>
<div class="line">    // executes on the current threadpool</div>
<div class="line">    tp-&gt;schedule(some_function, done_ch);</div>
<div class="line">    tp-&gt;schedule([=]</div>
<div class="line">    {   </div>
<div class="line">        // executes on the current threadpool, not the default</div>
<div class="line">        mce::parallel(some_function, done_ch);</div>
<div class="line">    });</div>
<div class="line">    </div>
<div class="line">    // execute on the default threadpool, not our custom threadpool</div>
<div class="line">    mce::parallel(some_function, done_ch);</div>
<div class="line"> </div>
<div class="line">    int r;</div>
<div class="line">    done_ch.recv(r);</div>
<div class="line">    done_ch.recv(r);</div>
<div class="line">    done_ch.recv(r);</div>
<div class="line">    tp-&gt;halt();</div>
<div class="line">    return 0;</div>
<div class="line">}</div>
</div><!-- fragment --><p>Terminal output: </p><div class="fragment"><div class="line">$ ./ex/example_014</div>
<div class="line">tp address[0x5572d91e4440]</div>
<div class="line">default threadpool address[0x5572d91e7760]</div>
<div class="line">threadpool address[0x5572d91e7760]</div>
<div class="line">threadpool address[0x5572d91e4440]</div>
<div class="line">threadpool address[0x5572d91e4440]</div>
</div><!-- fragment --><hr  />
 <h2><a class="anchor" id="autotoc_md62"></a>
balance</h2>
<div class="fragment"><div class="line">/// Schedule a coroutine(s), balancing CPU and communication needs</div>
<div class="line">template &lt;double RATIO_LIMIT=2.0, typename F, typename... As&gt;</div>
<div class="line">void balance(As&amp;&amp;... args);</div>
<div class="line"> </div>
<div class="line">/*</div>
<div class="line"> Return the balance ratio, set by compiler define: mceBALANCERATIO.</div>
<div class="line"> </div>
<div class="line"> This value can be set in the toplevel CMakeLists.txt</div>
<div class="line"> */</div>
<div class="line">double balance_ratio();</div>
</div><!-- fragment --><p><code>mce::balance</code> passes it's arguments to <code><a class="el" href="structmce_1_1scheduler.html#a013cd1b794606776a4c409f50ac437f1" title="schedule allocated coroutine(s)">mce::scheduler::schedule()</a></code> as-is. Executes its arguments as a concurrent coroutine(s). It attempts to intelligently schedule coroutines using the following algorithm:</p><ul>
<li>If not executing on a threadpool, schedules with <code><a class="el" href="threadpool_8hpp.html#af318b6bdd9e8e98245499ea41720208a" title="return the default threadpool&#39;s">mce::default_threadpool()</a></code></li>
<li>If executing on a threadpool, checks if the threadpool has a workload imbalance greater than <code><a class="el" href="threadpool_8hpp.html#af7de90dfe34f4f269b9c08d75bfcd0f1" title="return the balance ratio, set by compiler define: MCEBALANCERATIO">mce::balance_ratio()</a></code> (busiest_worker_load / least_busy_worker_load &gt;= <code><a class="el" href="threadpool_8hpp.html#af7de90dfe34f4f269b9c08d75bfcd0f1" title="return the balance ratio, set by compiler define: MCEBALANCERATIO">mce::balance_ratio()</a></code>)</li>
<li>If the workload ratio is found to be greater than the <code><a class="el" href="threadpool_8hpp.html#af7de90dfe34f4f269b9c08d75bfcd0f1" title="return the balance ratio, set by compiler define: MCEBALANCERATIO">mce::balance_ratio()</a></code>, the function is scheduled on the least busy worker</li>
<li>Otherwise the function is scheduled on the current thread's <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code></li>
</ul>
<p>This scheduling operation is the slowest of the high level algorithms. However, this slowness only occurs when <code><a class="el" href="threadpool_8hpp.html#a775daca1186f81e5410f2298abf5b832" title="Launch user function and optional arguments as a coroutine running on a scheduler....">mce::balance()</a></code> is called; once a coroutine is scheduled it operates at the same speed as other coroutines. As long as the primary bottleneck is not <em>launching</em> new coroutines, usage of this scheduling algorithm should not be a problem.</p>
<p>The operating theory of this algorithm is that if rebalancing occurs only when it is truly necessary, then the newly scheduled coroutines will themselves schedule additional operations on their current thread (instead of the thread of their parent coroutine), allowing the workload to balance naturally. Manual rebalancing will recur until the scheduled coroutines are naturally scheduling additional coroutines on their current threads in roughly equal amounts.</p>
<p><code><a class="el" href="threadpool_8hpp.html#a775daca1186f81e5410f2298abf5b832" title="Launch user function and optional arguments as a coroutine running on a scheduler....">mce::balance()</a></code> may provide better performance than <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code> or <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code> when both evenly distributed CPU usage and best-case communication latency are valued. An example of this may be in a program which runs for a long time, and may need to occasionally rebalance scheduling loads when scheduling new coroutines. If the developer determines this to be the case after performance analysis, they can generally replace usages of <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code> in their code with <code><a class="el" href="threadpool_8hpp.html#a775daca1186f81e5410f2298abf5b832" title="Launch user function and optional arguments as a coroutine running on a scheduler....">mce::balance()</a></code>, and further tweak their code if performance becomes an issue.</p>
<hr  />
 <h2><a class="anchor" id="autotoc_md64"></a>
custom scheduling</h2>
<p>The user can implement their own scheduling algorithm on a <code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool</a></code> by calling <code><a class="el" href="structmce_1_1threadpool.html#a16cb352e72cf6f475aaafac00bfb0b8b">mce::threadpool::workers()</a></code> which returns a <code>std::vector&lt;std::shared_ptr&lt;<a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a>&gt;&gt;</code> of schedulers running on worker threads managed by the <code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool</a></code> or by calling <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a>&amp; mce::threadpool::worker(size_t)</code> with a specific index to retrieve a given worker's scheduler. The user can then choose when and how to call <code><a class="el" href="structmce_1_1scheduler.html#a013cd1b794606776a4c409f50ac437f1" title="schedule allocated coroutine(s)">mce::scheduler::schedule()</a></code> to launch new coroutines.</p>
<p>A <em>potential</em> usecase for this is to guarantee that certain high level, root operations execute on different threads, such as launching various services during program startup. The scheduling algorithm <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">ccc::parallel()</a></code> generally attempts to accomplish this. However, <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">ccc::parallel()</a></code> do not have any way to distinguish between tasks passed to it, and may sometimes require user intervention to handle edgecases.</p>
<p>For instance, if a program's <code>main()</code> is launching distinct services at startup which need to be evenly distributed across threads, and those services <em>themselves</em> schedule on their associated <code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool()</a></code> (the <code><a class="el" href="threadpool_8hpp.html#af318b6bdd9e8e98245499ea41720208a" title="return the default threadpool&#39;s">mce::default_threadpool()</a></code>), the <code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool()</a></code> may accidentally schedule two root services on the same thread because <code>main()</code> is in competition with a running coroutine for access to <code>mce::threadpool::schedule()</code>.</p>
<p>Instead, by directly utilizing the vector of <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code>s returned from a call to <code><a class="el" href="structmce_1_1threadpool.html#a16cb352e72cf6f475aaafac00bfb0b8b">mce::threadpool::workers()</a></code>, the developer can ensure each coroutine is scheduled on the correct thread.</p>
<hr  />
 <h2><a class="anchor" id="autotoc_md66"></a>
yield</h2>
<p><code>void <a class="el" href="coroutine_8hpp.html#a43169feccceeceeb2b4ce668671196df">mce::yield()</a></code></p>
<p>Calls <code><a class="el" href="coroutine_8hpp.html#a43169feccceeceeb2b4ce668671196df">mce::co::yield()</a></code> if called from a running coroutine, otherwise nothing occurs. Calling this will allow other coroutines to run on the current thread because it will pause execution of the calling concurrent context.</p>
<p>Most usage of this operation will be internal to this framework. However, a user may sometimes need to call this operation directly, because it can be used to temporarily interrupt <em>long</em> running calls that are executing many operations continuously. Yielding out of such calls periodically will allow other coroutines to run.</p>
<p>Another example where explicitly calling <code><a class="el" href="coroutine_8hpp.html#a43169feccceeceeb2b4ce668671196df">yield()</a></code> is useful is when implementing non-blocking calls, where a coroutine can <code><a class="el" href="coroutine_8hpp.html#a43169feccceeceeb2b4ce668671196df">yield()</a></code> as soon as an operation fails before trying again (In fact, it is often best to <code><a class="el" href="coroutine_8hpp.html#a43169feccceeceeb2b4ce668671196df">yield()</a></code> after any non-blocking call, whether it succeeds or not to ensure the coroutine eventually relinquishes control to another coroutine).</p>
<hr  />
 <h2><a class="anchor" id="autotoc_md68"></a>
await</h2>
<div class="fragment"><div class="line">namespace mce {</div>
<div class="line"> </div>
<div class="line">// configurable value to specify the minimum number of threads that are kept</div>
<div class="line">// perpetually in the await workerpool, it can be set in CMakeLists.txt. Increasing</div>
<div class="line">// this value can minimize latency when many calls to mce::await() are being made.</div>
<div class="line">#define MCEMINAWAITPROCS</div>
<div class="line"> </div>
<div class="line">/*</div>
<div class="line"> @brief safely block caller while function executes and return the result </div>
<div class="line"> */</div>
<div class="line">template &lt;typename F, typename... As&gt; </div>
<div class="line">F_return_type await(F&amp;&amp; function, A&amp;&amp;... args);</div>
<div class="line"> </div>
<div class="line">/*</div>
<div class="line"> @return true if executing on an await() managed thread, else false</div>
<div class="line"> */</div>
<div class="line">bool is_await();</div>
<div class="line"> </div>
<div class="line">/*</div>
<div class="line"> @return the count of active await worker threads</div>
<div class="line"> */</div>
<div class="line">size_t await_count();</div>
<div class="line"> </div>
<div class="line">}</div>
</div><!-- fragment --><p> <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> allows coroutines running on a <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> to execute operating system blocking calls on a separate, dedicated thread, then resume operations back to the original thread and/or coroutine and seamlessly return the encapsulated function's return value.</p>
<p>This behavior allows other coroutines to execute while <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> is blocked, providing a simple mechanism to fix complex performance problems.</p>
<p><code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code>'s behavior is slightly different depending on if it is called within a coroutine running in a <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> or not. In the first case, the special behavior of executing the argument operation on a managed worker thread will occur, and the operation will be executed on a <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> running on that thread. In the second case, the procedure passed to <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> will be invoked immediately, on the calling thread. This is because standard threads are designed to handle blocking operations correctly.</p>
<p>It should be noted, that code executing inside a call to <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> will return the <code>std::shared_ptr&lt;<a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a>&gt;</code> associated with the <em>caller</em> of <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> when <code><a class="el" href="scheduler_8hpp.html#a617016feb0ee55df32bae9c248d6c263" title="returns true if calling scope is executing inside a running scheduler">mce::in_scheduler()</a></code>, <code><a class="el" href="scheduler_8hpp.html#a8c2a408455943622c5f71f3ff46e5068" title="returns a shared pointer to the scheduler the calling scope is running in">mce::this_scheduler()</a></code>, or <code>mce::this_scheduler_ref()</code> are invoked. Similarly, <code><a class="el" href="threadpool_8hpp.html#aff50fe740e3be609a5f698e6dbe8e65e" title="return a reference to the threadpool the calling code is executing in">mce::this_threadpool()</a></code> will return the <code>mce::shared_ptr&lt;<a class="el" href="structmce_1_1threadpool.html">mce::threadpool</a>&gt;</code> associated with the calling thread. This protects the user by allowing scheduling operations (such as <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code> and <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code>) to operate as if they were being called in the coroutine's original environment.</p>
<p>If <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> is executed outside of a coroutine (<code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>) then <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> will call its arguments on the current thread instead of executing on a worker thread. Similarly, a call to <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> within a task executing on an await worker thread will execute immediately. Otherwise <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> will attempt to execute on a thread in a pre-cached pool of worker threads.</p>
<p>The minimum count of background await worker threads is specified when compiling this library with compiler define <code>MCEMINAWAITPROCS</code>. If said define is not provided, it defaults to 1.</p>
<p>If no await worker thread is available a new, temporary worker thread will be created to execute the call.</p>
<p>If the argument function's return type is <code>void</code> then <code><a class="el" href="await_8hpp.html#a11e991f059963fa96c32a1dc33975e5f" title="Execute Callable potentially on a different thread and block current context until operation complete...">mce::await()</a></code> will return an <code>int</code> value of <code>0</code>.</p>
<p><a href="ex/src/example_001.cpp">example_001 source</a> </p><div class="fragment"><div class="line">#include &lt;fstream&gt;</div>
<div class="line">#include &lt;sstream&gt;</div>
<div class="line">#include &lt;string&gt;</div>
<div class="line">#include &lt;iostream&gt;</div>
<div class="line">#include &quot;mce.hpp&quot;</div>
<div class="line"> </div>
<div class="line">void read_file_content(std::string fname, mce::chan&lt;int&gt; done_ch) {</div>
<div class="line">    std::string fileContent;</div>
<div class="line"> </div>
<div class="line">    // create a function to execute in mce::await(). This function can *safely* </div>
<div class="line">    // access values on the coroutine&#39;s stack because the calling coroutine will</div>
<div class="line">    // be blocked while mce::await() is running.</div>
<div class="line">    auto read_file = [&amp;] {</div>
<div class="line">        std::ifstream file(fname); // open file</div>
<div class="line"> </div>
<div class="line">        if(file.is_open()) { </div>
<div class="line">            std::ostringstream ss;</div>
<div class="line">            ss &lt;&lt; file.rdbuf(); // extract file contents</div>
<div class="line">            fileContent = ss.str();</div>
<div class="line">            return true; // await() will return what the input function returns</div>
<div class="line">        } else { </div>
<div class="line">            return false; </div>
<div class="line">        }</div>
<div class="line">    };</div>
<div class="line"> </div>
<div class="line">    // If called from within a coroutine mce::await() will execute a function </div>
<div class="line">    // (with any function arguments) on a separate std::thread (blocking the </div>
<div class="line">    // caller of await() in a coroutine-safe way), but the return value will be </div>
<div class="line">    // provided to the caller of mce::await() when it returns.</div>
<div class="line">    //</div>
<div class="line">    // If mce::await() is instead executed on a normal thread, the function will be </div>
<div class="line">    // executed on that calling thread immediately. To the user&#39;s code, both </div>
<div class="line">    // cases will feel similar because they provide the same execution </div>
<div class="line">    // guarantees, blocking the caller while mce::await() is running.</div>
<div class="line">    //</div>
<div class="line">    // IE, mce::await() is primarily useful in a coroutine context to facilitate </div>
<div class="line">    // simple await() blocking, but in practice you can use it everwhere and the </div>
<div class="line">    // code should function similarly. </div>
<div class="line">    </div>
<div class="line">    if(mce::await(read_file)) { // wait for boolean return value of read_file function</div>
<div class="line">        std::cout &lt;&lt; &quot;file successfully read&quot; &lt;&lt; std::endl; </div>
<div class="line">    } else { </div>
<div class="line">        std::cout &lt;&lt; &quot;failed to read file&quot; &lt;&lt; std::endl; </div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    // print the file content </div>
<div class="line">    std::cout &lt;&lt; &quot;fileContent: &quot; &lt;&lt; fileContent &lt;&lt; std::endl;</div>
<div class="line">    done_ch.send(0);</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">int main(int argc, char** argv) {</div>
<div class="line">    std::string fname(&quot;my_filename.txt&quot;);</div>
<div class="line">    std::ofstream file(fname, std::ios_base::trunc);</div>
<div class="line"> </div>
<div class="line">    // ensure there is a file to read</div>
<div class="line">    if(file) {</div>
<div class="line">        file &lt;&lt; &quot;hello world!&quot;;</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    file.close();</div>
<div class="line"> </div>
<div class="line">    // launch asynchronous coroutine to read the file content </div>
<div class="line">    auto done_ch = mce::chan&lt;int&gt;::make(); </div>
<div class="line">    mce::parallel(read_file_content, fname, done_ch);</div>
<div class="line"> </div>
<div class="line">    // wait for coroutine to finish before the program exits</div>
<div class="line">    int r;</div>
<div class="line">    done_ch.recv(r);</div>
<div class="line">    return 0;</div>
<div class="line">}</div>
</div><!-- fragment --><p>Terminal output: </p><div class="fragment"><div class="line">$ ./ex/example_001</div>
<div class="line">file successfully read</div>
<div class="line">fileContent: hello world!</div>
<div class="line">$</div>
</div><!-- fragment --><hr  />
 <h2><a class="anchor" id="autotoc_md70"></a>
timer</h2>
<div class="fragment"><div class="line">// Launch a timer which will execute the timeout_handler at timeout </div>
<div class="line">template &lt;typename F, typename... As&gt;</div>
<div class="line">mce::timer_id mce::timer(mce::time_unit u, std::uint64_t count, F&amp;&amp; function, As&amp;&amp;...);</div>
<div class="line"> </div>
<div class="line">template &lt;typename F, typename... As&gt;</div>
<div class="line">mce::timer_id mce::timer(mce::duration d, F&amp;&amp; function, As&amp;&amp;...);</div>
<div class="line"> </div>
<div class="line">template &lt;typename F, typename... As&gt;</div>
<div class="line">mce::timer_id mce::timer(mce::time_point timeout, F&amp;&amp; function, As&amp;&amp;...);</div>
<div class="line"> </div>
<div class="line">// remove any running timer with a given timer_id, return true if successful, else return false</div>
<div class="line">bool mce::remove_timer(mce::timer_id id); </div>
<div class="line"> </div>
<div class="line">// return a count of running timers</div>
<div class="line">size_t mce::count_timers(); </div>
</div><!-- fragment --><p> These timer calls execute their callbacks on a threadpool with <code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code>, protecting the <code><a class="el" href="timer_8hpp.html#ae0c5845b438107a32cdde80510a3f5f7" title="Access to default mce::timer_service object.">default_timer_service()</a></code> thread from blocking on user callbacks.</p>
<p><code><a class="el" href="timer_8hpp.html#a4f3d651eea461040f92652f0f2455ea0" title="launch a timer with a Callable to be called on timeout">mce::timer()</a></code> calls accept any function <code>F</code> and any number of arguments <code>As...</code>. Given arguments <code>As...</code> will be bound to <code>F</code> and called together when the timer times out.</p>
<p><code>mce::time_unit</code> is an enumeration defined thus: </p><div class="fragment"><div class="line">enum time_unit </div>
<div class="line">{</div>
<div class="line">    hour,</div>
<div class="line">    minute,</div>
<div class="line">    second,</div>
<div class="line">    millisecond,</div>
<div class="line">    microsecond,</div>
<div class="line">    nanosecond</div>
<div class="line">};</div>
</div><!-- fragment --><p>And the <code>mce::duration</code> and <code>mce::time_point</code> types are defined thus: </p><div class="fragment"><div class="line">typedef std::chrono::steady_clock::time_point time_point; </div>
<div class="line">typedef std::chrono::steady_clock::duration duration;</div>
</div><!-- fragment --><p>Utility functions exist that can help create/manipulate these values: </p><div class="fragment"><div class="line">// return the current time as a mce::time_point</div>
<div class="line">mce::time_point mce::current_time(); </div>
<div class="line"> </div>
<div class="line">// return a mce::duration represent count instances of the time_unit</div>
<div class="line">mce::duration mce::get_duration(mce::time_unit u, size_t count); </div>
<div class="line"> </div>
<div class="line">// returns difference (p0-p1) as the given time_unit</div>
<div class="line">size_t mce::get_difference(mce::time_unit u, mce::time_point p0, mce::time_point p1); </div>
</div><!-- fragment --><hr  />
 <h2><a class="anchor" id="autotoc_md72"></a>
sleep</h2>
<div class="fragment"><div class="line">void mce::sleep(mce::time_unit u, std::uint64_t count);</div>
<div class="line">void mce::sleep(mce::duration d);</div>
</div><!-- fragment --><p> These function for both coroutines and threads. They implement blocking sleep behavior that allows other coroutines/threads to run.</p>
<hr  />
 <h2><a class="anchor" id="autotoc_md74"></a>
united synchronization primatives</h2>
<div class="fragment"><div class="line">class mce::mutex</div>
<div class="line">class mce::unitex_condition_variable</div>
</div><!-- fragment --><p> <code><a class="el" href="structmce_1_1mutex.html">mce::mutex</a></code> and <code><a class="el" href="structmce_1_1condition__variable.html">mce::condition_variable</a></code> function with nearly identical API to c++11 <code>std::mutex</code> and <code>std::condition_variable</code> (with the exception that it accepts an <code>std::unique_lock&lt;<a class="el" href="structmce_1_1mutex.html">mce::mutex</a>&gt;</code> instead of <code>std::unique_lock&lt;std::mutex&gt;</code> and <code><a class="el" href="structmce_1_1condition__variable.html">mce::condition_variable</a></code> uses <code>std::chrono::steady_clock</code> specifically).</p>
<p>The behavioral difference is that these objects block and synchronize correctly with any mixture of operating system threads and <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>s.</p>
<p>These objects are useful when integrating this library into existing codebases. The user can replace usage of <code>std::</code> versions with these <code>mce::</code> versions and launch their code with <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code>/<code><a class="el" href="threadpool_8hpp.html#a3ef2c7400038d8f79596c4ae2055df79" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::concurrent()</a></code> instead of <code>std::thread()</code>/<code>pthread</code> in order to improve program efficiency by leveraging coroutine context switching.</p>
<p>In general, atomic operations implemented with these primitives will be slower than channels. This is because channels directly use <code><a class="el" href="structmce_1_1spinlock.html" title="Core mechanism for atomic synchronization.">mce::spinlock</a></code>s (instead of mutexes) and <code><a class="el" href="structmce_1_1scheduler_1_1parkable.html" title="object containing information to block and unblock a coroutine (running in a scheduler) or thread">mce::scheduler::parkable</a></code> (instead of conditions) and only block the caller when truly necessary. In comparison, <code><a class="el" href="structmce_1_1mutex.html">mce::mutex</a></code> and <code><a class="el" href="structmce_1_1condition__variable.html">mce::condition_variable</a></code> operations may park the caller when spinlocking would be ideal. Additionally, the united primitives have extra features which add overhead to an algorithm which uses them rather than the simpler types.</p>
<p>However, it should be noted that unit testing shows that usage of these primitives to implement some concurrency-safe message queue may be <em>sometimes</em> preferable to standard channels. Specifically in situations when <em>many</em> system threads (not coroutines!) are attempting to access some concurrency-safe API then usage of <code><a class="el" href="structmce_1_1mutex.html">mce::mutex</a></code> provides better performance because it blocks the caller with a <code><a class="el" href="structmce_1_1scheduler_1_1parkable.html" title="object containing information to block and unblock a coroutine (running in a scheduler) or thread">mce::scheduler::parkable</a></code> when <code><a class="el" href="structmce_1_1mutex.html#af52ac8764fe0cbbe72c46ad4a97f4c87" title="Lock the mutex, blocking until lock is acquired.">mce::mutex::lock()</a></code> cannot immediately acquire the mutex, reducing lock contention.</p>
<p>As always, prefer measurement and profiling of program behavior when deciding if such an optimization is necessary.</p>
<p><a href="ex/src/example_018.cpp">example_018 source</a> </p><div class="fragment"><div class="line">// example_018</div>
<div class="line">#include &lt;iostream&gt;</div>
<div class="line">#include &lt;mutex&gt; // for std::unique_lock</div>
<div class="line">#include &quot;mce.hpp&quot;</div>
<div class="line"> </div>
<div class="line">int main()</div>
<div class="line">{</div>
<div class="line">    mce::mutex mtx;</div>
<div class="line">    mce::condition_variable cv;</div>
<div class="line">    bool flag = false;</div>
<div class="line">    int i = 0;</div>
<div class="line">    </div>
<div class="line">    std::unique_lock&lt;mce::mutex&gt; lk(mtx);</div>
<div class="line">    </div>
<div class="line">    std::thread t([&amp;]</div>
<div class="line">    {</div>
<div class="line">        {</div>
<div class="line">            std::unique_lock&lt;mce::mutex&gt; lk(mtx);</div>
<div class="line">            flag = true;</div>
<div class="line">            i = 1;</div>
<div class="line">        }</div>
<div class="line">        cv.notify_one();</div>
<div class="line">    });</div>
<div class="line">    </div>
<div class="line">    std::cout &lt;&lt; &quot;i: &quot; &lt;&lt; i &lt;&lt; std::endl;</div>
<div class="line">    </div>
<div class="line">    while(!flag){ cv.wait(lk); };</div>
<div class="line">    </div>
<div class="line">    std::cout &lt;&lt; &quot;i: &quot; &lt;&lt; i &lt;&lt; std::endl;</div>
<div class="line">    </div>
<div class="line">    t.join();</div>
<div class="line">    return 0;</div>
<div class="line">}</div>
</div><!-- fragment --><p>Terminal output: </p><div class="fragment"><div class="line">$ ./ex/example_018</div>
<div class="line">i: 0</div>
<div class="line">i: 1</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md75"></a>
Low Level Concurrency</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<ul>
<li><a href="#coroutine">coroutine</a></li>
<li><a href="#spinlock">spinlock</a></li>
<li><a href="#scheduler">scheduler</a></li>
<li><a href="#parkable">parkable</a></li>
<li><a href="#park">park</a></li>
<li><a href="#threadpool">threadpool</a></li>
<li><a href="#timer-service">timer service</a></li>
</ul>
<hr  />
 <h2><a class="anchor" id="autotoc_md77"></a>
coroutine</h2>
<div class="fragment"><div class="line">namespace mce {</div>
<div class="line"> </div>
<div class="line">struct coroutine {</div>
<div class="line">    /**</div>
<div class="line">     @brief construct an allocated coroutine from a Callable and arguments</div>
<div class="line">     @param cb a Callable</div>
<div class="line">     @param as arguments to pass to Callable</div>
<div class="line">     @return an allocated coroutine</div>
<div class="line">     */</div>
<div class="line">    template &lt;typename Callable, typename... As&gt;</div>
<div class="line">    static std::unique_ptr&lt;coroutine&gt; make(Callable&amp;&amp; cb, As&amp;&amp;... as);</div>
<div class="line"> </div>
<div class="line">    /// construct a coroutine from a thunk</div>
<div class="line">    template &lt;typename THUNK&gt; </div>
<div class="line">    mce::coroutine(THUNK&amp;&amp; th);</div>
<div class="line"> </div>
<div class="line">    /// construct a coroutine from a stack allocator and thunk</div>
<div class="line">    template &lt;typename StackAllocator, typename THUNK&gt;</div>
<div class="line">    coroutine(StackAllocator&amp;&amp; sa, THUNK&amp;&amp; th);</div>
<div class="line"> </div>
<div class="line">    coroutine(mce::coroutine&amp;&amp; rhs);</div>
<div class="line">    coroutine&amp; co::operator=(mce::coroutine&amp;&amp; rhs);</div>
<div class="line"> </div>
<div class="line">    /// Execute until thunk completes or yield() is called. If thunk is complete this function returns immediately.</div>
<div class="line">    void run(); </div>
<div class="line"> </div>
<div class="line">    /// Pause execution of the coroutine and return to run() caller.</div>
<div class="line">    void yield(); </div>
<div class="line"> </div>
<div class="line">    /// Returns true if thunk is complete, else false since the coroutine yielded early.</div>
<div class="line">    bool complete();  </div>
<div class="line">};</div>
<div class="line"> </div>
<div class="line">/// returns true if caller is a running coroutine, else false</div>
<div class="line">bool in_coroutine();</div>
<div class="line"> </div>
<div class="line">/// returns a pointer to the coroutine running on the current thread</div>
<div class="line">coroutine* this_coroutine();</div>
<div class="line"> </div>
<div class="line">/// Yield out of the current coroutine. No effect if running in a raw thread.</div>
<div class="line">void yield();</div>
<div class="line"> </div>
<div class="line">}</div>
</div><!-- fragment --><p> <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code> is the lowest level concurrent object managed by this library. It is a wrapper for the <code>boost::coroutines2::coroutine</code> object with some extra work done to expose the functionality into an external API. This is the object that all concurrent code is running inside of.</p>
<p><code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>'s templated constructors expect a Callable (either a function pointer or an object (potentially a lambda) with an operator() method that accepts no arguments). If the StackAllocator constructor is used it will allocate the coroutine stack using that object instead of the default allocator.</p>
<hr  />
 <h2><a class="anchor" id="autotoc_md79"></a>
spinlock</h2>
<div class="fragment"><div class="line">class mce::spinlock;</div>
<div class="line">void mce::spinlock::lock(); /// acquire the lock</div>
<div class="line">bool mce::spinlock::try_lock(); /// attempt to acquire the lock</div>
<div class="line">void mce::spinlock::unlock(); /// release the lock</div>
</div><!-- fragment --><p><code><a class="el" href="structmce_1_1spinlock.html" title="Core mechanism for atomic synchronization.">mce::spinlock</a></code> is the underlying atomic mechanism used by this library. Calls to <code>mce::spinlock::lock()</code> will cause the calling thread to continuously attempt to acquire the spinlock (does <em>NOT</em> wait on a condition).</p>
<p>It is an error to attempt to call <code>mce::spinlock::lock()</code> from a coroutine when the associated operation is not guaranteed to be non-blocking. That is, all usage of <code><a class="el" href="structmce_1_1spinlock.html" title="Core mechanism for atomic synchronization.">mce::spinlock</a></code> should be written in such a way that it is guaranteed to unlock in a small amount of time. Failing to implement this way can cause deadlock.</p>
<p>It <em>is</em> possible (though <em>highly</em> discouraged) to call <code>mce::spinlock::try_lock()</code> continuously by a coroutine like thus: </p><div class="fragment"><div class="line">while(!lk.try_lock()) </div>
<div class="line">{</div>
<div class="line">    mce::yield(); // allow other coroutines to run</div>
<div class="line">}</div>
</div><!-- fragment --><p>In such a scenario it is (almost certainly) better to block the coroutine using a <code><a class="el" href="structmce_1_1scheduler_1_1parkable.html" title="object containing information to block and unblock a coroutine (running in a scheduler) or thread">mce::scheduler::parkable</a></code> and unblock the coroutine with some other code in the future, because parking causes coroutines to stop using CPU and is very fast.</p>
<hr  />
 <h2><a class="anchor" id="autotoc_md81"></a>
scheduler</h2>
<div class="fragment"><div class="line">namespace mce {</div>
<div class="line"> </div>
<div class="line">struct lifecycle {</div>
<div class="line">    enum state </div>
<div class="line">    {</div>
<div class="line">        ready, /// initial state after construction or after resume() is called</div>
<div class="line">        running, /// run() has been called and is executing coroutines</div>
<div class="line">        suspended, /// temporarily halted</div>
<div class="line">        halted /// permanently halted by a call to halt() </div>
<div class="line">    };</div>
<div class="line">};</div>
<div class="line"> </div>
<div class="line">struct scheduler {</div>
<div class="line">    // see dedicated section explaining this object</div>
<div class="line">    struct park </div>
<div class="line">    {</div>
<div class="line">        struct continuation;</div>
<div class="line">        static void suspend(continuation&amp; c);</div>
<div class="line">    };</div>
<div class="line"> </div>
<div class="line">    // see dedicated section explaining this object</div>
<div class="line">    struct parkable;</div>
<div class="line"> </div>
<div class="line">    // return the scheduler&#39;s state</div>
<div class="line">    lifecycle::state get_state();</div>
<div class="line"> </div>
<div class="line">    // allocate and initialize a scheduler</div>
<div class="line">    static std::shared_ptr&lt;scheduler&gt; make(); </div>
<div class="line"> </div>
<div class="line">    // Block caller and start executing coroutines scheduled on the scheduler.</div>
<div class="line">    // </div>
<div class="line">    // Returns `true` if suspend() is called and `false` if halt() is called, </div>
<div class="line">    /// allowing run() to be called in a loop:</div>
<div class="line">    //</div>
<div class="line">    // while(my_scheduler-&gt;run())</div>
<div class="line">    // {</div>
<div class="line">    //    // do other things after suspend()</div>
<div class="line">    // }</div>
<div class="line">    //</div>
<div class="line">    // // do other things after halt()</div>
<div class="line">    //</div>
<div class="line">    //</div>
<div class="line">    // Additional calls to `run()` while the scheduler is suspended will </div>
<div class="line">    // block the caller of `run()` in such a way that it executes no coroutines.</div>
<div class="line">    // The caller will remain blocked until either `resume()` or `halt()` is </div>
<div class="line">    // called.</div>
<div class="line">    bool run(); </div>
<div class="line"> </div>
<div class="line">    // Cause current caller of run() to return early with the value `true`.</div>
<div class="line">    // Subsequent calls to `run()` will block waiting until halt() or resume() is </div>
<div class="line">    // called. During this time, no coroutines will be executed.</div>
<div class="line">    // </div>
<div class="line">    // Useful for putting schedulers &quot;to sleep&quot; in programs which have lifecycle </div>
<div class="line">    // management.</div>
<div class="line">    bool suspend(); </div>
<div class="line"> </div>
<div class="line">    // Resume suspended evaluation of coroutines on the scheduler (future or </div>
<div class="line">    // current calls to run() on the suspended scheduler will resume coroutine </div>
<div class="line">    // evaluation)</div>
<div class="line">    bool resume(); </div>
<div class="line"> </div>
<div class="line">    // Forever halt running coroutines and synchronize with exitting run(), which </div>
<div class="line">    // will return `false` to its caller</div>
<div class="line">    void halt(); </div>
<div class="line"> </div>
<div class="line">    /**</div>
<div class="line">     @brief Schedule allocated coroutines</div>
<div class="line"> </div>
<div class="line">     Arguments to this function can be:</div>
<div class="line">     - an allocated `std::unique_ptr&lt;mce::coroutine&gt;`</div>
<div class="line">     - an iterable container of allocated `std::unique_ptr&lt;mce::coroutine&gt;`s</div>
<div class="line"> </div>
<div class="line">     After the above argument types, any remaining arguments can be:</div>
<div class="line">     - a Callable (followed by any arguments for the Callable) </div>
<div class="line"> </div>
<div class="line">     The user can manually construct allocated </div>
<div class="line">     `std::unique_ptr&lt;mce::coroutine&gt;`s with `mce::coroutine::make()`</div>
<div class="line"> </div>
<div class="line">     Multi-argument schedule()s hold the scheduler&#39;s lock throughout (they are </div>
<div class="line">     simultaneously scheduled).</div>
<div class="line"> </div>
<div class="line">     @param a the first argument</div>
<div class="line">     @param as any remaining arguments</div>
<div class="line">     */</div>
<div class="line">    template &lt;typename A, typename... As&gt;</div>
<div class="line">    void schedule(A&amp;&amp; a, As&amp;&amp;... as);</div>
<div class="line"> </div>
<div class="line">    /// an object which represents the scheduler&#39;s workload</div>
<div class="line">    struct measurement </div>
<div class="line">    {</div>
<div class="line">        measurement();</div>
<div class="line">        measurement(const measurement&amp; rhs);</div>
<div class="line">        measurement(measurement&amp;&amp; rhs);</div>
<div class="line">        measurement(size_t enqueued, size_t scheduled);</div>
<div class="line"> </div>
<div class="line">        measurement&amp; operator=(const measurement&amp; rhs);</div>
<div class="line">        measurement&amp; operator=(measurement&amp;&amp; rhs);</div>
<div class="line"> </div>
<div class="line">        bool operator ==(const measurement&amp; rhs);</div>
<div class="line">        bool operator &lt;(const measurement&amp; rhs);</div>
<div class="line">        bool operator &lt;=(const measurement&amp; rhs);</div>
<div class="line"> </div>
<div class="line">        /// convert to a directly comparable fundamental type</div>
<div class="line">        operator size_t() const;</div>
<div class="line">        </div>
<div class="line">        /// count of all scheduled coroutines, blocked or enqueued</div>
<div class="line">        size_t scheduled() const;</div>
<div class="line"> </div>
<div class="line">        /// count of coroutines actively enqueued for execution</div>
<div class="line">        size_t enqueued() const;</div>
<div class="line">        </div>
<div class="line">        /// count of coroutines blocked on the scheduler</div>
<div class="line">        size_t blocked() const;</div>
<div class="line">    };</div>
<div class="line"> </div>
<div class="line">    /// return a value representing the current scheduling load</div>
<div class="line">    measurement measure();</div>
<div class="line"> </div>
<div class="line">    /// return a copy of this scheduler&#39;s shared pointer by conversion</div>
<div class="line">    operator std::shared_ptr&lt;scheduler&gt;();</div>
<div class="line">};</div>
<div class="line"> </div>
<div class="line">/// returns true if calling code is executing inside a scheduler, else false</div>
<div class="line">bool in_scheduler();</div>
<div class="line"> </div>
<div class="line">/**</div>
<div class="line"> Return scheduler that this code is running inside of. Retaining a copy of this </div>
<div class="line"> scheduler can be used to keep the scheduler in scope during blocking operations.</div>
<div class="line"> */</div>
<div class="line">scheduler&amp; this_scheduler(); </div>
<div class="line"> </div>
<div class="line">}</div>
</div><!-- fragment --><p> <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> is the object responsible for scheduling and executing <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>s on an individual operating system thread. It can be used on any arbitrary thread, including the main thread. Its public api is both threadsafe and coroutine-safe (the API can be called by <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>s already running on the <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code>). It is even safe to run a <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> inside a <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code> running on another <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code>!</p>
<p><a href="ex/src/example_019.cpp">example_019 source</a> </p><div class="fragment"><div class="line">// example_019</div>
<div class="line">#include &lt;iostream&gt;</div>
<div class="line">#include &quot;mce.hpp&quot;</div>
<div class="line"> </div>
<div class="line">int main()</div>
<div class="line">{</div>
<div class="line">    std::shared_ptr&lt;mce::scheduler&gt; cs = mce::scheduler::make();                                   </div>
<div class="line">    mce::chan&lt;int&gt; done_ch = mce::chan&lt;int&gt;::make(); </div>
<div class="line">    </div>
<div class="line">    auto recv_function = [](mce::chan&lt;int&gt; done_ch)</div>
<div class="line">    {                                                                              </div>
<div class="line">        int r;</div>
<div class="line">        done_ch.recv(r);</div>
<div class="line">        std::cout &lt;&lt; &quot;recv done&quot; &lt;&lt; std::endl;</div>
<div class="line">        mce::this_scheduler().halt();                                              </div>
<div class="line">    };                </div>
<div class="line"> </div>
<div class="line">    auto send_function = [&amp;](mce::chan&lt;int&gt; done_ch)</div>
<div class="line">    { </div>
<div class="line">        mce::this_scheduler().schedule(recv_function, done_ch);</div>
<div class="line">        std::cout &lt;&lt; &quot;send done&quot; &lt;&lt; std::endl;</div>
<div class="line">        done_ch.send(0);</div>
<div class="line">    };</div>
<div class="line"> </div>
<div class="line">    cs-&gt;schedule(send_function, done_ch); // schedule send_function for exection</div>
<div class="line">    cs-&gt;run(); // execute coroutines on the current thread until halt() is called</div>
<div class="line">    return 0;</div>
<div class="line">}</div>
</div><!-- fragment --><p>Terminal output: </p><div class="fragment"><div class="line">$ ./ex/example_019</div>
<div class="line">send done</div>
<div class="line">recv done</div>
</div><!-- fragment --><hr  />
 <h2><a class="anchor" id="autotoc_md83"></a>
parkable</h2>
<div class="fragment"><div class="line">struct mce::scheduler::parkable;</div>
<div class="line"> </div>
<div class="line">// constructor</div>
<div class="line">mce::scheduler::parkable();</div>
<div class="line"> </div>
<div class="line">// Block the calling coroutine or system thread until `unpark()` is called. </div>
<div class="line">// Argument lk is unlocked before blocking.</div>
<div class="line">template &lt;typename LOCK&gt;</div>
<div class="line">void mce::scheduler::parkable::park(LOCK&amp; lk);</div>
<div class="line"> </div>
<div class="line">// Unblock and reschedule the blocked operation.</div>
<div class="line">// Argument lk is locked before unblocking .</div>
<div class="line">template &lt;typename LOCK&gt;</div>
<div class="line">void mce::scheduler::parkable::unpark(LOCK&amp; lk);</div>
</div><!-- fragment --><p><code><a class="el" href="structmce_1_1scheduler_1_1parkable.html" title="object containing information to block and unblock a coroutine (running in a scheduler) or thread">mce::scheduler::parkable</a></code> is a special struct that is deeply integrated with the <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> object. It is responsible for blocking (all operations ceasing) and unblocking (resuming operations) of a calling <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code> OR regular system thread. All blocking operations (that do not busy wait) implemented by this library utilize this object.</p>
<p>For best results, <code><a class="el" href="structmce_1_1scheduler_1_1parkable.html" title="object containing information to block and unblock a coroutine (running in a scheduler) or thread">mce::scheduler::parkable</a></code> objects should be used by <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>s scheduled on a <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> or on a non-coroutine thread. Technically speaking, this operation will function with a raw <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code> <em>not</em> running in a scheduler, but calling <code>park()</code> in this situation will just cause <code>mce::coroutine::resume()</code> to immediately <code><a class="el" href="structmce_1_1coroutine.html#a06e17cb7d354cc576f8f1e3a7f555d53" title="Pause execution and return to run() caller.">mce::coroutine::yield()</a></code> until <code>unpark()</code> is called.</p>
<p><code><a class="el" href="structmce_1_1scheduler_1_1parkable.html#aafb8951d3727e784e1acf4d7548d67ea" title="blocking call until unpark, unlocks and relocks given lock as necessary">mce::scheduler::parkable::park()</a></code> accepts any object capable of calling <code>lock()</code> or <code>unlock()</code>. <code>park()</code> assumes its argument object is already locked. <code>park()</code> will <code>unlock()</code> its argument lock just before blocking the caller. <code>unpark()</code> will <code>relock()</code> <code>park()</code>'s argument when it is reschuled (<code>unpark()</code>'s argument is used to synchronize with the resumed caller or <code>park()</code>).</p>
<p>The side effects of locking and unlocking need to be clearly understood by the implementor, to avoid causing deadlock in coroutines. Typical usage is to pass a locked <code>std::unique_lock&lt;<a class="el" href="structmce_1_1spinlock.html" title="Core mechanism for atomic synchronization.">mce::spinlock</a>&gt;</code> to <code>park()</code>, but other usages and types are acceptable.</p>
<p>When a <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code> running in a <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> blocks with a <code><a class="el" href="structmce_1_1scheduler_1_1parkable.html" title="object containing information to block and unblock a coroutine (running in a scheduler) or thread">mce::scheduler::parkable</a></code>, the <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> assigns the <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>'s <code>unique_ptr</code> to the <code>parkable</code>. If the <code>parkable</code> is on the <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>'s stack (either directly or as a shared pointer) this creates a chain of circular memory where the <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>'s allocated stack hold the parkable in memory, and the <code>parkable</code> holds the <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>'s stack in memory. When a <code>parkable</code> is <code>unpark()</code>ed, the <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>'s <code>unique_ptr</code> is returned to the <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code>, allowing it's lifecycle to continue.</p>
<p>This is an <em>IMPORTANT</em> detail, if a <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code> is never <code>unpark()</code>ed, it is effectively a <em>memory leak</em>. This means the user must properly <code>close()</code> channels or otherwise ensure <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>s are not blocked when operations cease.</p>
<p>It is technically possible to use a <code>parkable</code> allocated somewhere outside of the <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>'s stack, though it is generally unnecessary to do so, as it can generally be created on a the parked coroutine or thread's stack.</p>
<hr  />
 <h2><a class="anchor" id="autotoc_md85"></a>
park</h2>
<div class="fragment"><div class="line">struct mce::scheduler::park </div>
<div class="line">{</div>
<div class="line">    struct continuation</div>
<div class="line">    {</div>
<div class="line">        // pointer to coroutine storage location</div>
<div class="line">        std::unique_ptr&lt;mce::coroutine&gt;* coroutine; </div>
<div class="line"> </div>
<div class="line">        // memory to source scheduler storage location</div>
<div class="line">        std::weak_ptr&lt;mce::scheduler&gt;* source;</div>
<div class="line"> </div>
<div class="line">        // arbitrary memory</div>
<div class="line">        void* memory; </div>
<div class="line"> </div>
<div class="line">        // cleanup procedure executed after acquiring coroutine</div>
<div class="line">        void(*cleanup)(void*); </div>
<div class="line">    };</div>
<div class="line"> </div>
<div class="line">    /*</div>
<div class="line">     @brief the fundamental operation required for blocking a coroutine running in a scheduler</div>
<div class="line"> </div>
<div class="line">     Direct usage of this is not recommended unless it is truly required, prefer</div>
<div class="line">     scheduler::parkable instead.</div>
<div class="line"> </div>
<div class="line">     It is an error if this is called outside of a coroutine running in a </div>
<div class="line">     scheduler.</div>
<div class="line">    */</div>
<div class="line">    static void suspend(continuation&amp; c);</div>
<div class="line">};</div>
</div><!-- fragment --><p>This object is the lowest level coroutine blocking mechanism. It is utilized by the higher level <code><a class="el" href="structmce_1_1scheduler_1_1parkable.html" title="object containing information to block and unblock a coroutine (running in a scheduler) or thread">mce::scheduler::parkable</a></code> object. In comparison, this is a more basic type only for blocking coroutines, and requires more manual work because of its more generic nature. However, this type is exposed in case it is required by user code.</p>
<p>All higher level coroutine blocking mechanics are built on this structure. A mutable reference to a <code>park::continuation</code> is passed to <code>park::suspend()</code>, which will register the continuation with the <code>scheduler</code> running on the current thread and <code><a class="el" href="coroutine_8hpp.html#a43169feccceeceeb2b4ce668671196df">yield()</a></code> control to said <code>scheduler</code>, suspending execution of the calling coroutine.</p>
<p>When the <code>scheduler</code> resumes control, it will assign the just running coroutine to the dereferenced <code>std::unique_ptr&lt;<a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a>&gt;</code> <code>coroutine</code>. It will then assign its weak_ptr to the dereferenced <code>std::weak_ptr&lt;scheduler&gt;</code> <code>source</code>, allowing the owner of the continuation to re-schedule the coroutine on the source scheduler.</p>
<p>After passing the coroutine to its destination, the specified <code>cleanup()</code> method will be called with <code>memory</code>. This can be any operation, accepting any data as an argument. A common usecase is to unlock an atomic lock object.</p>
<p>At this point, control of the given <code>coroutine</code> completely leaves the <code>scheduler</code>, it is up to the destination code to decide what to do with the <code>coroutine</code>.</p>
<hr  />
 <h2><a class="anchor" id="autotoc_md87"></a>
threadpool</h2>
<div class="fragment"><div class="line">namespace mce {</div>
<div class="line"> </div>
<div class="line">struct threadpool </div>
<div class="line">{</div>
<div class="line">    /**</div>
<div class="line">     @brief construct an allocated threadpool with a count of worker threads</div>
<div class="line">     */</div>
<div class="line">    static std::shared_ptr&lt;threadpool&gt; make(size_t worker_count = 0);</div>
<div class="line"> </div>
<div class="line">    /// halt(), join() and delete all workers</div>
<div class="line">    ~threadpool();</div>
<div class="line"> </div>
<div class="line">    /// return the workers&#39; state</div>
<div class="line">    lifecycle::state get_state();</div>
<div class="line"> </div>
<div class="line">    /// suspend all workers, returning true if all workers suspend() == true, else false</div>
<div class="line">    bool suspend();</div>
<div class="line"> </div>
<div class="line">    /// resume all workers</div>
<div class="line">    void resume();</div>
<div class="line"> </div>
<div class="line">    /// halt all workers</div>
<div class="line">    void halt();</div>
<div class="line"> </div>
<div class="line">    /// return the count of worker threads</div>
<div class="line">    size_t size();</div>
<div class="line"> </div>
<div class="line">    /// access the scheduler for a worker at a given index</div>
<div class="line">    scheduler&amp; worker(size_t idx);</div>
<div class="line"> </div>
<div class="line">    /// return the least busy worker scheduler at time of call</div>
<div class="line">    scheduler&amp; worker();</div>
<div class="line"> </div>
<div class="line">    /**</div>
<div class="line">     This operation is more expensive than calling worker(). It should be</div>
<div class="line">     unnecessary in most cases to call this method, but it is provided in case</div>
<div class="line">     some sort of high level scheduler management is desired by the user and </div>
<div class="line">     access to all of `std::vector`&#39;s utility functionality would be beneficial.</div>
<div class="line"> </div>
<div class="line">     @return the schedulers for all running worker threads</div>
<div class="line">     */</div>
<div class="line">    std::vector&lt;std::shared_ptr&lt;scheduler&gt;&gt; workers();</div>
<div class="line"> </div>
<div class="line">    /// return a copy of this threadpool&#39;s shared pointer by conversion</div>
<div class="line">    operator std::shared_ptr&lt;threadpool&gt;();</div>
<div class="line">};</div>
<div class="line"> </div>
<div class="line">// returns true if calling thread is a threadpool worker</div>
<div class="line">bool in_threadpool();</div>
<div class="line"> </div>
<div class="line">// returns the threadpool for the calling threadpool worker thread</div>
<div class="line">threadpool&amp; this_threadpool(); </div>
<div class="line"> </div>
<div class="line">/// return true if default_threadpool() can be safely called, else false</div>
<div class="line">bool default_threadpool_enabled();</div>
<div class="line"> </div>
<div class="line">// configurable value to specify the number of threads in the default workerpool, it can be set in CMakeLists.txt</div>
<div class="line">#define MCEMAXPROCS </div>
<div class="line"> </div>
<div class="line">// return the process-wide default threadpool used by higher level parallel mechanisms</div>
<div class="line">threadpool&amp; default_threadpool();</div>
<div class="line"> </div>
<div class="line">}</div>
</div><!-- fragment --><p>Creating a <code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool</a></code> object will launch 1 or more operating system worker threads with running <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code>s. If no number of workers are specified, this function internally decides how many workers to allocate for best performance. This provides fine tuned control over how many threads are available to a subset of coroutines to execute on.</p>
<p>When a <code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool</a></code> is destroyed, the <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code>s on its managed threads are halted and the worker threads joined.</p>
<p><code>mce::threadpool::schedule</code> schedules a function to be executed as a coroutine on the threadpool. A pointer to the threadpool associated with the current thread (either user created or default) can be retrieved with <code><a class="el" href="threadpool_8hpp.html#aff50fe740e3be609a5f698e6dbe8e65e" title="return a reference to the threadpool the calling code is executing in">mce::this_threadpool()</a></code>.</p>
<p><a href="ex/src/example_020.cpp">example_020 source</a> </p><div class="fragment"><div class="line">// example_020  </div>
<div class="line">#include &lt;iostream&gt;</div>
<div class="line">#include &quot;mce.hpp&quot;</div>
<div class="line"> </div>
<div class="line">int main()</div>
<div class="line">{</div>
<div class="line">    mce::chan&lt;int&gt; ch = mce::chan&lt;int&gt;::make();</div>
<div class="line">    mce::chan&lt;int&gt; done_ch = mce::chan&lt;int&gt;::make();</div>
<div class="line">    </div>
<div class="line">    auto f = [](mce::chan&lt;int&gt; done_ch, mce::chan&lt;int&gt; ch)</div>
<div class="line">    {</div>
<div class="line">        // schedule coroutine by indirectly using the threadpool</div>
<div class="line">        mce::this_threadpool().worker().schedule([ch]{ ch.send(0); });</div>
<div class="line">        </div>
<div class="line">        int x;</div>
<div class="line">        ch.recv(x);</div>
<div class="line">        </div>
<div class="line">        mce::this_threadpool().worker().schedule([=]{ done_ch.send(0); });</div>
<div class="line">    };</div>
<div class="line">    </div>
<div class="line">    // start a threadpool with 2 worker threads</div>
<div class="line">    std::shared_ptr&lt;mce::threadpool&gt; tp = mce::threadpool::make(2);</div>
<div class="line">    </div>
<div class="line">    // schedule coroutine by directly using the threadpool</div>
<div class="line">    tp-&gt;schedule(f, done_ch, ch);</div>
<div class="line">   </div>
<div class="line">    int r;</div>
<div class="line">    done_ch.recv(r);</div>
<div class="line">    tp-&gt;halt();</div>
<div class="line">    std::cout &lt;&lt; &quot;received done confirmation&quot; &lt;&lt; std::endl;</div>
<div class="line">    return 0;</div>
<div class="line">}</div>
</div><!-- fragment --><p>Terminal output: </p><div class="fragment"><div class="line">$ ./ex/example_020</div>
<div class="line">received done confirmation</div>
</div><!-- fragment --><p>A process-wide default <code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool</a></code> can be generated/accessed as necessary via <code><a class="el" href="threadpool_8hpp.html#af318b6bdd9e8e98245499ea41720208a" title="return the default threadpool&#39;s">mce::default_threadpool()</a></code>. It is the <code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool()</a></code> accessed by calls to <code>mce::parallel</code> and other similar procedures. As such it is important in programs which can pause and resume their operations that <code>suspend()</code> and <code>resume()</code> be called during the appropriate process-wide lifecycle state change functions.</p>
<p>NOTE: If a <code>scheduler</code> managed by a <code>threadpool</code> has its <code>suspend()</code>/<code>resume()</code>/<code>halt()</code> methods called, it will <em>actually</em> call the <code>threadpool</code>'s implementations of the same methods!</p>
<p>The thread worker count of <code><a class="el" href="threadpool_8hpp.html#af318b6bdd9e8e98245499ea41720208a" title="return the default threadpool&#39;s">mce::default_threadpool()</a></code> can be specified when compiling your software by modifying CMakeLists.txt variable <code>MCEMAXPROCS</code>. If <code>MCEMAXPROCS</code> is left undefined, the library will be compiled with an internally determined worker count (which aims to achieve peak CPU throughput).</p>
<hr  />
 <h2><a class="anchor" id="autotoc_md89"></a>
timer service</h2>
<p>Timer types &amp; utility functions: </p><div class="fragment"><div class="line">enum time_unit </div>
<div class="line">{</div>
<div class="line">    hour,</div>
<div class="line">    minute,</div>
<div class="line">    second,</div>
<div class="line">    millisecond,</div>
<div class="line">    microsecond,</div>
<div class="line">    nanosecond</div>
<div class="line">};</div>
<div class="line"> </div>
<div class="line">typedef std::chrono::steady_clock::time_point time_point; </div>
<div class="line">typedef std::chrono::steady_clock::duration duration;</div>
<div class="line"> </div>
<div class="line">struct timer_id;</div>
<div class="line"> </div>
<div class="line">mce::duration get_duration(mce::time_unit u, size_t count);</div>
<div class="line">size_t get_time_point_difference(mce::time_unit u, mce::time_point p0, mce::time_point p1);</div>
<div class="line">mce::time_point current_time();</div>
</div><!-- fragment --><p><code>timer_service</code> functions: </p><div class="fragment"><div class="line">mce::timer_service::timer_service(); </div>
<div class="line"> </div>
<div class="line">// Shutdown and join with asynchronous timer service if shutdown() has </div>
<div class="line">// not been previously called.</div>
<div class="line">mce::timer_service::~timer_service(); </div>
<div class="line"> </div>
<div class="line">void mce::timer_service::start(); // start timer service on current thread</div>
<div class="line">void mce::timer_service::ready(); // blocks until service is running</div>
<div class="line">void mce::timer_service::shutdown(); // inform service to shutdown and join with service</div>
<div class="line"> </div>
<div class="line">// returns unsigned integer size_t representing the id of the</div>
<div class="line">// created timer. Pass this id to remove() to delete the timer (if it </div>
<div class="line">// has not timed out).</div>
<div class="line"> </div>
<div class="line">// start a timer </div>
<div class="line">template &lt;typename THUNK&gt;</div>
<div class="line">timer_id timer(const mce::time_point&amp; timeout, THUNK&amp;&amp; timeout_handler);</div>
<div class="line">template &lt;typename THUNK&gt;</div>
<div class="line">timer_id timer(const mce::duration&amp; d, THUNK&amp;&amp; timeout_handler);</div>
<div class="line">template &lt;typename THUNK&gt;</div>
<div class="line">timer_id timer(const time_unit u, size_t count, THUNK&amp;&amp; timeout_handler);</div>
<div class="line"> </div>
<div class="line">// return true if timer is running, else false</div>
<div class="line">bool mce::timer_service::running(mce::timer_id id); </div>
<div class="line"> </div>
<div class="line">// Remove a running timer. Returns true if timer was found and removed, </div>
<div class="line">// else returns false.</div>
<div class="line">bool mce::timer_service::remove(mce::timer_id id);</div>
<div class="line"> </div>
<div class="line">// Remove all pending timers</div>
<div class="line">void mce::timer_service::clear();</div>
<div class="line"> </div>
<div class="line">// Returns a pointer to default timer service, which is guaranteed to be running on </div>
<div class="line">// another thread by the time this call returns. It is recommended that the user NOT</div>
<div class="line">// use this service directly, instead using high level mce::timer()/mce::sleep()</div>
<div class="line">// operations</div>
<div class="line">mce:timer_service&amp; mce::default_timer_service(); </div>
</div><!-- fragment --><p> A tiny asynchronous timer service implementation. This service is not designed to work inside of coroutines and is unsafe to do so, it will almost certainly cause deadlock. To safely interact with coroutines, extra work must be done so that the timeout_handler executes threadsafe code (which can include rescheduling a coroutine or notifying a coroutine via a channel).</p>
<p>Start the service: </p><div class="fragment"><div class="line">mce::timer_service my_timer_service;</div>
<div class="line">std::thread thd([&amp;]{ my_timer_service.start(); });</div>
<div class="line">my_timer_service.ready(); // block until started</div>
</div><!-- fragment --><p>Usage is as simple as: </p><div class="fragment"><div class="line">mce::timer_id tid = my_timer_service.timer(mce::time_unit::microsecond, </div>
<div class="line">                                           microsecs_till_timeout, </div>
<div class="line">                                           my_timeout_handler);</div>
</div><!-- fragment --><p>The timer can be synchronously removed (if it is not already executing) with: </p><div class="fragment"><div class="line">my_timer_service.remove(tid);</div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md90"></a>
Concurrent Lifecycle Management</h1>
<p><img src="img/mercury_icon_tiny.png" alt="mercury_icon" class="inline"/></p>
<p>See <code>suspend()</code> and <code>resume()</code> procedures in the following sections for how to pause/unpause execution of coroutines:</p><ul>
<li><a href="#scheduler">scheduler</a></li>
<li><a href="#threadpool">threadpool</a></li>
</ul>
<p>Execution of <code><a class="el" href="structmce_1_1coroutine.html">mce::coroutine</a></code>s scheduled on <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code>s are started with calls to <code>run()</code> and permanently halted with <code>halt()</code>.</p>
<p><code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool</a></code>s automatically call <code>run()</code> on their internally managed threads when they are created. However, the user must call <code>halt()</code> on the <code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool</a></code> to permanently halt its worker threads. The exception to this is the default threadpool (<code><a class="el" href="threadpool_8hpp.html#af318b6bdd9e8e98245499ea41720208a" title="return the default threadpool&#39;s">mce::default_threadpool()</a></code>) which will call <code>halt()</code> when the process ends.</p>
<p>The user is responsible for calling <code>threadpool::suspend()</code>/<code>threadpool::resume()</code> on <em>all</em> <code>threadpool</code>s as necessary (including on the <code><a class="el" href="threadpool_8hpp.html#af318b6bdd9e8e98245499ea41720208a" title="return the default threadpool&#39;s">mce::default_threadpool()</a></code>!). <code>scheduler::suspend()</code>/<code>scheduler::resume()</code> will also need to be called for any manually managed <code><a class="el" href="structmce_1_1scheduler.html" title="object responsible for scheduling and executing coroutines">mce::scheduler</a></code> instances (IE, those not created by a <code>threadpool</code>). Call <code>suspend()</code> when <code>coroutine</code> execution must temporarily cease, and call <code>resume()</code> when execution should resume.</p>
<p>Use this information when implementing process lifecycle procedures related to process state like: init/wakeup/run/sleep/shutdown.</p>
<p>For example, <code><a class="el" href="threadpool_8hpp.html#af318b6bdd9e8e98245499ea41720208a" title="return the default threadpool&#39;s">mce::default_threadpool()</a></code> returns the default <code><a class="el" href="structmce_1_1threadpool.html">mce::threadpool</a></code> used by most high level features (like <code><a class="el" href="threadpool_8hpp.html#a60e70d3b46c34e94edf9f8e00442bffb" title="Launch user function and optional arguments as a coroutine running on a scheduler.">mce::parallel()</a></code>), and will need to be <code>suspend()</code>ed/<code>resume()</code>ed by the user when the process is supposed to sleep/wakeup. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
